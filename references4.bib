@article{cochard_rna_2022,
	title = {{RNA} at the surface of phase-separated condensates impacts their size and number},
	volume = {121},
	issn = {0006-3495},
	url = {https://www.cell.com/biophysj/abstract/S0006-3495(22)00242-9},
	doi = {10.1016/j.bpj.2022.03.032},
	language = {English},
	number = {9},
	urldate = {2022-06-24},
	journal = {Biophysical Journal},
	author = {Cochard, Audrey and Navarro, Marina Garcia-Jove and Piroska, Leonard and Kashida, Shunnichi and Kress, Michel and Weil, Dominique and Gueroui, Zoher},
	month = may,
	year = {2022},
	pmid = {35364105},
	note = {Publisher: Elsevier},
	pages = {1675--1690}
}

@article{khater_caveolae_2019,
	title = {Caveolae and scaffold detection from single molecule localization microscopy data using deep learning},
	volume = {14},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0211659},
	doi = {10.1371/journal.pone.0211659},
	abstract = {Caveolae are plasma membrane invaginations whose formation requires caveolin-1 (Cav1), the adaptor protein polymerase I, and the transcript release factor (PTRF or CAVIN1). Caveolae have an important role in cell functioning, signaling, and disease. In the absence of CAVIN1/PTRF, Cav1 forms non-caveolar membrane domains called scaffolds. In this work, we train machine learning models to automatically distinguish between caveolae and scaffolds from single molecule localization microscopy (SMLM) data. We apply machine learning algorithms to discriminate biological structures from SMLM data. Our work is the first that is leveraging machine learning approaches (including deep learning models) to automatically identifying biological structures from SMLM data. In particular, we develop and compare three binary classification methods to identify whether or not a given 3D cluster of Cav1 proteins is a caveolae. The first uses a random forest classifier applied to 28 hand-crafted/designed features, the second uses a convolutional neural net (CNN) applied to a projection of the point clouds onto three planes, and the third uses a PointNet model, a recent development that can directly take point clouds as its input. We validate our methods on a dataset of super-resolution microscopy images of PC3 prostate cancer cells labeled for Cav1. Specifically, we have images from two cell populations: 10 PC3 and 10 CAVIN1/PTRF-transfected PC3 cells (PC3-PTRF cells) that form caveolae. We obtained a balanced set of 1714 different cellular structures. Our results show that both the random forest on hand-designed features and the deep learning approach achieve high accuracy in distinguishing the intrinsic features of the caveolae and non-caveolae biological structures. More specifically, both random forest and deep CNN classifiers achieve classification accuracy reaching 94\% on our test set, while the PointNet model only reached 83\% accuracy. We also discuss the pros and cons of the different approaches.},
	language = {en},
	number = {8},
	urldate = {2022-05-17},
	journal = {PLOS ONE},
	author = {Khater, Ismail M. and Aroca-Ouellette, Stephane T. and Meng, Fanrui and Nabi, Ivan Robert and Hamarneh, Ghassan},
	month = aug,
	year = {2019},
	note = {Publisher: Public Library of Science},
	keywords = {Cell membranes, Cellular structures and organelles, Coated pits, Deep learning, Imaging techniques, Machine learning, Membrane proteins, Prostate cancer},
	pages = {e0211659},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/UFXV63EX/Khater et al. - 2019 - Caveolae and scaffold detection from single molecu.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/9YJTQ2ZG/article.html:text/html},
}

@article{savulescu_interrogating_2021,
	title = {Interrogating {RNA} and protein spatial subcellular distribution in {smFISH} data with {DypFISH}},
	volume = {1},
	issn = {2667-2375},
	url = {https://www.sciencedirect.com/science/article/pii/S266723752100120X},
	doi = {10.1016/j.crmeth.2021.100068},
	abstract = {Advances in single-cell RNA sequencing have allowed for the identification of cellular subtypes on the basis of quantification of the number of transcripts in each cell. However, cells might also differ in the spatial distribution of molecules, including RNAs. Here, we present DypFISH, an approach to quantitatively investigate the subcellular localization of RNA and protein. We introduce a range of analytical techniques to interrogate single-molecule RNA fluorescence in situ hybridization (smFISH) data in combination with protein immunolabeling. DypFISH is suited to study patterns of clustering of molecules, the association of mRNA-protein subcellular localization with microtubule organizing center orientation, and interdependence of mRNA-protein spatial distributions. We showcase how our analytical tools can achieve biological insights by utilizing cell micropatterning to constrain cellular architecture, which leads to reduction in subcellular mRNA distribution variation, allowing for the characterization of their localization patterns. Furthermore, we show that our method can be applied to physiological systems such as skeletal muscle fibers.},
	language = {en},
	number = {5},
	urldate = {2022-05-17},
	journal = {Cell Reports Methods},
	author = {Savulescu, Anca F. and Brackin, Robyn and Bouilhol, Emmanuel and Dartigues, Benjamin and Warrell, Jonathan H. and Pimentel, Mafalda R. and Beaume, Nicolas and Fortunato, Isabela C. and Dallongeville, Stephane and Boulle, MikaÃ«l and Soueidan, Hayssam and Agou, Fabrice and Schmoranzer, Jan and Olivo-Marin, Jean-Christophe and Franco, Claudio A. and Gomes, Edgar R. and Nikolski, Macha and Mhlanga, Musa M.},
	month = sep,
	year = {2021},
	keywords = {image analysis, microfabricated patterns, Ripley's K, RNA subcellular localization, single-molecule FISH},
	pages = {100068},
	file = {Full Text:/Users/arthur/Zotero/storage/MQNNAMFZ/Savulescu et al. - 2021 - Interrogating RNA and protein spatial subcellular .pdf:application/pdf;ScienceDirect Snapshot:/Users/arthur/Zotero/storage/MIXSHL38/S266723752100120X.html:text/html},
}

@article{samacoits_computational_2018,
	title = {A computational framework to study sub-cellular {RNA} localization},
	volume = {9},
	copyright = {2018 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-018-06868-w},
	doi = {10.1038/s41467-018-06868-w},
	abstract = {RNA localization is a crucial process for cellular function and can be quantitatively studied by single molecule FISH (smFISH). Here, we present an integrated analysis framework to analyze sub-cellular RNA localization. Using simulated images, we design and validate a set of features describing different RNA localization patterns including polarized distribution, accumulation in cell extensions or foci, at the cell membrane or nuclear envelope. These features are largely invariant to RNA levels, work in multiple cell lines, and can measure localization strength in perturbation experiments. Most importantly, they allow classification by supervised and unsupervised learning at unprecedented accuracy. We successfully validate our approach on representative experimental data. This analysis reveals a surprisingly high degree of localization heterogeneity at the single cell level, indicating a dynamic and plastic nature of RNA localization.},
	language = {en},
	number = {1},
	urldate = {2022-05-17},
	journal = {Nature Communications},
	author = {Samacoits, Aubin and Chouaib, Racha and Safieddine, Adham and Traboulsi, Abdel-Meneem and Ouyang, Wei and Zimmer, Christophe and Peter, Marion and Bertrand, Edouard and Walter, Thomas and Mueller, Florian},
	month = nov,
	year = {2018},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Cellular imaging, Fluorescence imaging, Fluorescence in situ hybridization, Software},
	pages = {4584},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/BGITRCI2/Samacoits et al. - 2018 - A computational framework to study sub-cellular RN.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/8EDHVHMY/s41467-018-06868-w.html:text/html},
}

@article{stoeger_computer_2015,
	series = {Inferring {Gene} {Regulatory} {Interactions} from {Quantitative} {High}-{Throughput} {Measurements}},
	title = {Computer vision for image-based transcriptomics},
	volume = {85},
	issn = {1046-2023},
	url = {https://www.sciencedirect.com/science/article/pii/S1046202315002091},
	doi = {10.1016/j.ymeth.2015.05.016},
	abstract = {Single-cell transcriptomics has recently emerged as one of the most promising tools for understanding the diversity of the transcriptome among single cells. Image-based transcriptomics is unique compared to other methods as it does not require conversion of RNA to cDNA prior to signal amplification and transcript quantification. Thus, its efficiency in transcript detection is unmatched by other methods. In addition, image-based transcriptomics allows the study of the spatial organization of the transcriptome in single cells at single-molecule, and, when combined with superresolution microscopy, nanometer resolution. However, in order to unlock the full power of image-based transcriptomics, robust computer vision of single molecules and cells is required. Here, we shortly discuss the setup of the experimental pipeline for image-based transcriptomics, and then describe in detail the algorithms that we developed to extract, at high-throughput, robust multivariate feature sets of transcript molecule abundance, localization and patterning in tens of thousands of single cells across the transcriptome. These computer vision algorithms and pipelines can be downloaded from: https://github.com/pelkmanslab/ImageBasedTranscriptomics.},
	language = {en},
	urldate = {2021-09-14},
	journal = {Methods},
	author = {Stoeger, Thomas and Battich, Nico and Herrmann, Markus D. and Yakimovich, Yauhen and Pelkmans, Lucas},
	month = sep,
	year = {2015},
	keywords = {FISH, High-throughput, hybridization, Image-based transcriptomics, Localization, Segmentation, Single-cell, Single-molecule, Subcellular},
	pages = {44--53},
	file = {Accepted Version:/Users/arthur/Zotero/storage/NND4A8GY/Stoeger et al. - 2015 - Computer vision for image-based transcriptomics.pdf:application/pdf;ScienceDirect Snapshot:/Users/arthur/Zotero/storage/CE7Y78IB/S1046202315002091.html:text/html},
}

@article{mcquin_cellprofiler_2018,
	title = {{CellProfiler} 3.0: {Next}-generation image processing for biology},
	volume = {16},
	issn = {1545-7885},
	shorttitle = {{CellProfiler} 3.0},
	url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2005970},
	doi = {10.1371/journal.pbio.2005970},
	abstract = {CellProfiler has enabled the scientific research community to create flexible, modular image analysis pipelines since its release in 2005. Here, we describe CellProfiler 3.0, a new version of the software supporting both whole-volume and plane-wise analysis of three-dimensional (3D) image stacks, increasingly common in biomedical research. CellProfilerâs infrastructure is greatly improved, and we provide a protocol for cloud-based, large-scale image processing. New plugins enable running pretrained deep learning models on images. Designed by and for biologists, CellProfiler equips researchers with powerful computational tools via a well-documented user interface, empowering biologists in all fields to create quantitative, reproducible image analysis workflows.},
	language = {en},
	number = {7},
	urldate = {2021-09-13},
	journal = {PLOS Biology},
	author = {McQuin, Claire and Goodman, Allen and Chernyshev, Vasiliy and Kamentsky, Lee and Cimini, Beth A. and Karhohs, Kyle W. and Doan, Minh and Ding, Liya and Rafelski, Susanne M. and Thirstrup, Derek and Wiegraebe, Winfried and Singh, Shantanu and Becker, Tim and Caicedo, Juan C. and Carpenter, Anne E.},
	month = jul,
	year = {2018},
	note = {Publisher: Public Library of Science},
	keywords = {Biologists, Blastocysts, Cell staining, Computer software, Deep learning, Image analysis, Image processing, Open source software},
	pages = {e2005970},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/S8F4J3CM/McQuin et al. - 2018 - CellProfiler 3.0 Next-generation image processing.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/DCPQKCNU/article.html:text/html},
}

@article{held_cellcognition_2010,
	title = {{CellCognition}: time-resolved phenotype annotation in high-throughput live cell imaging},
	volume = {7},
	issn = {1548-7105},
	shorttitle = {{CellCognition}},
	doi = {10.1038/nmeth.1486},
	abstract = {Fluorescence time-lapse imaging has become a powerful tool to investigate complex dynamic processes such as cell division or intracellular trafficking. Automated microscopes generate time-resolved imaging data at high throughput, yet tools for quantification of large-scale movie data are largely missing. Here we present CellCognition, a computational framework to annotate complex cellular dynamics. We developed a machine-learning method that combines state-of-the-art classification with hidden Markov modeling for annotation of the progression through morphologically distinct biological states. Incorporation of time information into the annotation scheme was essential to suppress classification noise at state transitions and confusion between different functional states with similar morphology. We demonstrate generic applicability in different assays and perturbation conditions, including a candidate-based RNA interference screen for regulators of mitotic exit in human cells. CellCognition is published as open source software, enabling live-cell imaging-based screening with assays that directly score cellular dynamics.},
	language = {eng},
	number = {9},
	journal = {Nature Methods},
	author = {Held, Michael and Schmitz, Michael H. A. and Fischer, Bernd and Walter, Thomas and Neumann, Beate and Olma, Michael H. and Peter, Matthias and Ellenberg, Jan and Gerlich, Daniel W.},
	month = sep,
	year = {2010},
	pmid = {20693996},
	keywords = {Artificial Intelligence, Automation, Cell Shape, Cell Survival, Cells, Computational Biology, Computer Simulation, Fluorescence, HeLa Cells, Humans, Image Processing, Computer-Assisted, Kinetics, Markov Chains, Mitosis, Molecular Imaging, Phenotype, Software, Time Factors},
	pages = {747--754},
	file = {Submitted Version:/Users/arthur/Zotero/storage/2XXN2YDL/Held et al. - 2010 - CellCognition time-resolved phenotype annotation .pdf:application/pdf},
}

@article{berg_ilastik_2019,
	title = {ilastik: interactive machine learning for (bio)image analysis},
	volume = {16},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	shorttitle = {ilastik},
	url = {https://www.nature.com/articles/s41592-019-0582-9},
	doi = {10.1038/s41592-019-0582-9},
	abstract = {We present ilastik, an easy-to-use interactive tool that brings machine-learning-based (bio)image analysis to end users without substantial computational expertise. It contains pre-defined workflows for image segmentation, object classification, counting and tracking. Users adapt the workflows to the problem at hand by interactively providing sparse training annotations for a nonlinear classifier. ilastik can process data in up to five dimensions (3D, time and number of channels). Its computational back end runs operations on-demand wherever possible, allowing for interactive prediction on data larger than RAM. Once the classifiers are trained, ilastik workflows can be applied to new data from the command line without further user interaction. We describe all ilastik workflows in detail, including three case studies and a discussion on the expected performance.},
	language = {en},
	number = {12},
	urldate = {2021-09-13},
	journal = {Nature Methods},
	author = {Berg, Stuart and Kutra, Dominik and Kroeger, Thorben and Straehle, Christoph N. and Kausler, Bernhard X. and Haubold, Carsten and Schiegg, Martin and Ales, Janez and Beier, Thorsten and Rudy, Markus and Eren, Kemal and Cervantes, Jaime I. and Xu, Buote and Beuttenmueller, Fynn and Wolny, Adrian and Zhang, Chong and Koethe, Ullrich and Hamprecht, Fred A. and Kreshuk, Anna},
	month = dec,
	year = {2019},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Number: 12
Primary\_atype: Reviews
Publisher: Nature Publishing Group
Subject\_term: Image processing;Machine learning;Software
Subject\_term\_id: image-processing;machine-learning;software},
	pages = {1226--1232},
	file = {Snapshot:/Users/arthur/Zotero/storage/P8PQ3T45/s41592-019-0582-9.html:text/html;Submitted Version:/Users/arthur/Zotero/storage/HCJBK3TP/Berg et al. - 2019 - ilastik interactive machine learning for (bio)ima.pdf:application/pdf},
}

@article{shariff_automated_2010,
	title = {Automated {Image} {Analysis} for {High}-{Content} {Screening} and {Analysis}},
	volume = {15},
	issn = {2472-5552, 2472-5560},
	url = {https://slas-discovery.org/article/S2472-5552(22)07949-7/fulltext},
	doi = {10.1177/1087057110370894},
	language = {English},
	number = {7},
	urldate = {2022-05-17},
	journal = {SLAS Discovery},
	author = {Shariff, Aabid and Kangas, Joshua and Coelho, Luis Pedro and Quinn, Shannon and Murphy, Robert F.},
	month = aug,
	year = {2010},
	note = {Publisher: Elsevier},
	keywords = {bioimage informatics, high-content screening, image analysis, machine learning, subcellular location},
	pages = {726--734},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/SMIWB58A/Shariff et al. - 2010 - Automated Image Analysis for High-Content Screenin.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/5NP4SQTV/fulltext.html:text/html},
}

@article{laux_interactive_2020,
	title = {Interactive machine learning for fast and robust cell profiling},
	volume = {15},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0237972},
	doi = {10.1371/journal.pone.0237972},
	abstract = {Automated profiling of cell morphology is a powerful tool for inferring cell function. However, this technique retains a high barrier to entry. In particular, configuring image processing parameters for optimal cell profiling is susceptible to cognitive biases and dependent on user experience. Here, we use interactive machine learning to identify the optimum cell profiling configuration that maximises quality of the cell profiling outcome. The process is guided by the user, from whom a rating of the quality of a cell profiling configuration is obtained. We use Bayesian optimisation, an established machine learning algorithm, to learn from this information and automatically recommend the next configuration to examine with the aim of maximising the quality of the processing or analysis. Compared to existing interactive machine learning tools that require domain expertise for per-class or per-pixel annotations, we rely on usersâ explicit assessment of output quality of the cell profiling task at hand. We validated our interactive approach against the standard human trial-and-error scheme to optimise an object segmentation task using the standard software CellProfiler. Our toolkit enabled rapid optimisation of an object segmentation pipeline, increasing the quality of object segmentation over a pipeline optimised through trial-and-error. Users also attested to the ease of use and reduced cognitive load enabled by our machine learning strategy over the standard approach. We envision that our interactive machine learning approach can enhance the quality and efficiency of pipeline optimisation to democratise image-based cell profiling.},
	language = {en},
	number = {9},
	urldate = {2022-05-17},
	journal = {PLOS ONE},
	author = {Laux, Lisa and Cutiongco, Marie F. A. and Gadegaard, Nikolaj and Jensen, BjÃ¸rn Sand},
	month = sep,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Computational pipelines, Focal adhesions, Graphics pipelines, Image processing, Imaging techniques, Machine learning, Machine learning algorithms, Optimization},
	pages = {e0237972},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/D8BLLLDY/Laux et al. - 2020 - Interactive machine learning for fast and robust c.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/C4BEHCLH/article.html:text/html},
}


@article{ljosa_introduction_2009,
	title = {Introduction to the {Quantitative} {Analysis} of {Two}-{Dimensional} {Fluorescence} {Microscopy} {Images} for {Cell}-{Based} {Screening}},
	volume = {5},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000603},
	doi = {10.1371/journal.pcbi.1000603},
	language = {en},
	number = {12},
	urldate = {2022-05-17},
	journal = {PLOS Computational Biology},
	author = {Ljosa, Vebjorn and Carpenter, Anne E.},
	month = dec,
	year = {2009},
	note = {Publisher: Public Library of Science},
	keywords = {Bright field microscopy, Computer imaging, Computer software, Fluorescence imaging, Image analysis, Imaging techniques, Open source software, Software tools},
	pages = {e1000603},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/S5PGJIZ9/Ljosa and Carpenter - 2009 - Introduction to the Quantitative Analysis of Two-D.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/DABIY6B9/article.html:text/html},
}

@article{battich_image-based_2013,
	title = {Image-based transcriptomics in thousands of single human cells at single-molecule resolution},
	volume = {10},
	copyright = {2013 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/nmeth.2657},
	doi = {10.1038/nmeth.2657},
	abstract = {An automated experimental and software pipeline for large-scale FISH enables spatial transcriptomics in thousands of single human cells at single-molecule resolution.},
	language = {en},
	number = {11},
	urldate = {2022-05-17},
	journal = {Nature Methods},
	author = {Battich, Nico and Stoeger, Thomas and Pelkmans, Lucas},
	month = nov,
	year = {2013},
	note = {Number: 11
Publisher: Nature Publishing Group},
	keywords = {Fluorescence in situ hybridization, Gene expression, High-throughput screening, Transcriptomics},
	pages = {1127--1133},
	file = {Snapshot:/Users/arthur/Zotero/storage/MWWSYUMV/nmeth.html:text/html},
}

@article{battich_control_2015,
	title = {Control of {Transcript} {Variability} in {Single} {Mammalian} {Cells}},
	volume = {163},
	issn = {0092-8674, 1097-4172},
	url = {https://www.cell.com/cell/abstract/S0092-8674(15)01498-1},
	doi = {10.1016/j.cell.2015.11.018},
	language = {English},
	number = {7},
	urldate = {2022-05-17},
	journal = {Cell},
	author = {Battich, Nico and Stoeger, Thomas and Pelkmans, Lucas},
	month = dec,
	year = {2015},
	pmid = {26687353},
	note = {Publisher: Elsevier},
	pages = {1596--1610},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/RF7ZFEJG/Battich et al. - 2015 - Control of Transcript Variability in Single Mammal.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/8SDAPT2S/S0092-8674(15)01498-1.html:text/html},
}

@article{CHOUAIB_2020,
	title = {A Dual Protein-mRNA Localization Screen Reveals Compartmentalized Translation and Widespread Co-translational RNA Targeting},
	journal = {Developmental Cell},
	volume = {54},
	number = {6},
	pages = {773-791.e5},
	year = {2020},
	issn = {1534-5807},
	doi = {https://doi.org/10.1016/j.devcel.2020.07.010},
	url = {https://www.sciencedirect.com/science/article/pii/S1534580720305840},
	author = {Racha Chouaib and Adham Safieddine and Xavier Pichon and Arthur Imbert and Oh Sung Kwon and Aubin Samacoits and Abdel-Meneem Traboulsi and Marie-CÃ©cile Robert and Nikolay Tsanov and Emeline Coleno and Ina Poser and Christophe Zimmer and Anthony Hyman and HervÃ© {Le Hir} and Kazem Zibara and Marion Peter and Florian Mueller and Thomas Walter and Edouard Bertrand},
	keywords = {RNA localization, local translation, RNA transport, smFISH, translation factories, co-translational targeting, ASPM, Beta-catenin},
	abstract = {Summary
	Local translation allows spatial control of gene expression. Here, we performed a dual protein-mRNA localization screen, using smFISH on 523 human cell lines expressing GFP-tagged genes. 32 mRNAs displayed specific cytoplasmic localizations with local translation at unexpected locations, including cytoplasmic protrusions, cell edges, endosomes, Golgi, the nuclear envelope, and centrosomes, the latter being cell-cycle-dependent. Automated classification of mRNA localization patterns revealed a high degree of intercellular heterogeneity. Surprisingly, mRNA localization frequently required ongoing translation, indicating widespread co-translational RNA targeting. Interestingly, while P-body accumulation was frequent (15 mRNAs), four mRNAs accumulated in foci that were distinct structures. These foci lacked the mature protein, but nascent polypeptide imaging showed that they were specialized translation factories. For Î²-catenin, foci formation was regulated by Wnt, relied on APC-dependent polysome aggregation, and led to nascent protein degradation. Thus, translation factories uniquely regulate nascent protein metabolism and create a fine granular compartmentalization of translation.}
}

@article{safieddine_choreography_2021,
	title = {A choreography of centrosomal {mRNAs} reveals a conserved localization mechanism involving active polysome transport},
	volume = {12},
	copyright = {2021 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-21585-7},
	doi = {10.1038/s41467-021-21585-7},
	abstract = {Local translation allows for a spatial control of gene expression. Here, we use high-throughput smFISH to screen centrosomal protein-coding genes, and we describe 8 human mRNAs accumulating at centrosomes. These mRNAs localize at different stages during cell cycle with a remarkable choreography, indicating a finely regulated translational program at centrosomes. Interestingly, drug treatments and reporter analyses reveal a common translation-dependent localization mechanism requiring the nascent protein. Using ASPM and NUMA1 as models, single mRNA and polysome imaging reveals active movements of endogenous polysomes towards the centrosome at the onset of mitosis, when these mRNAs start localizing. ASPM polysomes associate with microtubules and localize by either motor-driven transport or microtubule pulling. Remarkably, the Drosophila orthologs of the human centrosomal mRNAs also localize to centrosomes and also require translation. These data identify a conserved family of centrosomal mRNAs that localize by active polysome transport mediated by nascent proteins.},
	language = {en},
	number = {1},
	urldate = {2022-06-28},
	journal = {Nature Communications},
	author = {Safieddine, Adham and Coleno, Emeline and Salloum, Soha and Imbert, Arthur and Traboulsi, Abdel-Meneem and Kwon, Oh Sung and Lionneton, Frederic and Georget, Virginie and Robert, Marie-CÃ©cile and Gostan, Thierry and Lecellier, Charles-Henri and Chouaib, Racha and Pichon, Xavier and Le Hir, HervÃ© and Zibara, Kazem and Mueller, Florian and Walter, Thomas and Peter, Marion and Bertrand, Edouard},
	month = mar,
	year = {2021},
	keywords = {High-throughput screening, Molecular imaging, RNA metabolism},
	pages = {1352},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/L2W9WBYV/Safieddine et al. - 2021 - A choreography of centrosomal mRNAs reveals a cons.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/QDU24VXV/s41467-021-21585-7.html:text/html},
}

@article{pichon_kinesin_2021,
	title = {The kinesin {KIF1C} transports {APC}-dependent {mRNAs} to cell protrusions},
	volume = {27},
	issn = {1355-8382, 1469-9001},
	url = {http://rnajournal.cshlp.org/content/27/12/1528},
	doi = {10.1261/rna.078576.120},
	abstract = {RNA localization and local translation are important for numerous cellular functions. In mammals, a class of mRNAs localize to cytoplasmic protrusions in an APC-dependent manner, with roles during cell migration. Here, we investigated this localization mechanism. We found that the KIF1C motor interacts with APC-dependent mRNAs and is required for their localization. Live cell imaging revealed rapid, active transport of single mRNAs over long distances that requires both microtubules and KIF1C. Two-color imaging directly revealed single mRNAs transported by single KIF1C motors, with the 3â²UTR being sufficient to trigger KIF1C-dependent RNA transport and localization. Moreover, KIF1C remained associated with peripheral, multimeric RNA clusters and was required for their formation. These results reveal a widespread RNA transport pathway in mammalian cells, in which the KIF1C motor has a dual role in transporting RNAs and clustering them within cytoplasmic protrusions. Interestingly, KIF1C also transports its own mRNA, suggesting a possible feedback loop acting at the level of mRNA transport.},
	language = {en},
	number = {12},
	urldate = {2022-06-28},
	journal = {RNA},
	author = {Pichon, Xavier and Moissoglu, Konstadinos and Coleno, Emeline and Wang, Tianhong and Imbert, Arthur and Robert, Marie-CÃ©cile and Peter, Marion and Chouaib, Racha and Walter, Thomas and Mueller, Florian and Zibara, Kazem and Bertrand, Edouard and Mili, Stavroula},
	month = jan,
	year = {2021},
	pmid = {34493599},
	keywords = {cytoplasmic protrusions, local translation, RNA localization, RNA transport},
	pages = {1528--1544},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/BKYDP248/Pichon et al. - 2021 - The kinesin KIF1C transports APC-dependent mRNAs t.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/3T2XJ7P9/1528.html:text/html},
}

@inproceedings{dubois_deep_2019,
	title = {A {Deep} {Learning} {Approach} {To} {Identify} {mRNA} {Localization} {Patterns}},
	doi = {10.1109/ISBI.2019.8759235},
	abstract = {The localization of messenger RNA (mRNA) molecules inside cells play an important role for the local control of gene expression. However, the localization patterns of many mRNAs remain unknown and poorly understood. Single Molecule Fluorescence in Situ Hybridization (smFISH) allows for the visualization of individual mRNA molecules in cells. This method is now scalable and can be applied in High Content Screening (HCS) mode. Here, we propose a computational workflow based on deep convolutional neural networks trained on simulated data to identify different localization patterns from large-scale smFISH data.},
	booktitle = {2019 {IEEE} 16th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI} 2019)},
	author = {Dubois, RÃ©my and Imbert, Arthur and SamacoÃ¯ts, Aubin and Peter, Marion and Bertrand, Edouard and MÃ¼ller, Florian and Walter, Thomas},
	month = apr,
	year = {2019},
	note = {ISSN: 1945-8452},
	keywords = {Data visualization, Deep learning, Deep Learning, Feature extraction, Gene expression, High Content Screening, image simulation, Proteins, RNA, RNA localization, Spatial Transcriptomics, Three-dimensional displays},
	pages = {1386--1390},
	file = {IEEE Xplore Abstract Record:/Users/arthur/Zotero/storage/HD8ISRQA/8759235.html:text/html},
}

@article{stueland_rdi_2019,
	title = {{RDI} {Calculator}: {An} {Analysis} {Tool} to {Assess} {RNA} {Distributions} in {Cells}},
	volume = {9},
	copyright = {2019 The Author(s)},
	issn = {2045-2322},
	shorttitle = {{RDI} {Calculator}},
	url = {https://www.nature.com/articles/s41598-019-44783-2},
	doi = {10.1038/s41598-019-44783-2},
	abstract = {Localization of RNAs to various subcellular destinations has emerged as a widely used mechanism that regulates a large proportion of transcripts in polarized cells. A number of methodologies have been developed that allow detection and imaging of RNAs at single-molecule resolution. However, methodologies to quantitatively describe RNA distributions are limited. Such approaches usually rely on the identification of cytoplasmic and nuclear boundaries which are used as reference points. Here, we describe an automated, interactive image analysis program that facilitates the accurate generation of cellular outlines from single cells and the subsequent calculation of metrics that quantify how a population of RNA molecules is distributed in the cell cytoplasm. We apply this analysis to mRNAs in mouse and human cells to demonstrate how these metrics can highlight differences in the distribution patterns of distinct RNA species. We further discuss considerations for the practical use of this tool. This program provides a way to facilitate and expedite the analysis of subcellular RNA localization for mechanistic and functional studies.},
	language = {en},
	number = {1},
	urldate = {2022-06-28},
	journal = {Scientific Reports},
	author = {Stueland, Michael and Wang, Tianhong and Park, Hye Yoon and Mili, Stavroula},
	month = jun,
	year = {2019},
	keywords = {Fluorescence in situ hybridization, Molecular imaging, RNA transport, Software},
	pages = {8267},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/MMPK4UPG/Stueland et al. - 2019 - RDI Calculator An Analysis Tool to Assess RNA Dis.pdf:application/pdf},
}

@article{Iandola_2016,
	author    = {Forrest N. Iandola and
			   Matthew W. Moskewicz and
			   Khalid Ashraf and
			   Song Han and
			   William J. Dally and
			   Kurt Keutzer},
	title     = {SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and {\textless}1MB model size},
	journal   = {CoRR},
	volume    = {abs/1602.07360},
	year      = {2016},
	url       = {http://arxiv.org/abs/1602.07360},
	eprinttype = {arXiv},
	eprint    = {1602.07360},
	timestamp = {Fri, 20 Nov 2020 16:16:06 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/IandolaMAHDK16.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{vandermaaten_2008,
	author  = {Laurens van der Maaten and Geoffrey Hinton},
	title   = {Visualizing Data using t-SNE},
	journal = {Journal of Machine Learning Research},
	year    = {2008},
	volume  = {9},
	number  = {86},
	pages   = {2579--2605},
	url     = {http://jmlr.org/papers/v9/vandermaaten08a.html}
}

@article{wattenberg2016,
	author = {Wattenberg, Martin and ViÃ©gas, Fernanda and Johnson, Ian},
	title = {How to Use t-SNE Effectively},
	journal = {Distill},
	year = {2016},
	url = {http://distill.pub/2016/misread-tsne},
	doi = {10.23915/distill.00002}
}

@article{olah2017feature,
	author = {Olah, Chris and Mordvintsev, Alexander and Schubert, Ludwig},
	title = {Feature Visualization},
	journal = {Distill},
	year = {2017},
	note = {https://distill.pub/2017/feature-visualization},
	doi = {10.23915/distill.00007}
}

@article{olah2018the,
	author = {Olah, Chris and Satyanarayan, Arvind and Johnson, Ian and Carter, Shan and Schubert, Ludwig and Ye, Katherine and Mordvintsev, Alexander},
	title = {The Building Blocks of Interpretability},
	journal = {Distill},
	year = {2018},
	note = {https://distill.pub/2018/building-blocks},
	doi = {10.23915/distill.00010}
}

@inproceedings{Yarin_2016,
	author = {Gal, Yarin and Ghahramani, Zoubin},
	title = {Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning},
	year = {2016},
	publisher = {JMLR.org},
	abstract = {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs - extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and nonlinearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.},
	booktitle = {Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48},
	pages = {1050â1059},
	numpages = {10},
	location = {New York, NY, USA},
	series = {ICML'16}
}

@inproceedings{Rosanne_2018,
	author = {Liu, Rosanne and Lehman, Joel and Molino, Piero and Petroski Such, Felipe and Frank, Eric and Sergeev, Alex and Yosinski, Jason},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {An intriguing failing of convolutional neural networks and the CoordConv solution},
	url = {https://proceedings.neurips.cc/paper/2018/file/60106888f8977b71e1f15db7bc9a88d1-Paper.pdf},
	volume = {31},
	year = {2018}
}

@InProceedings{Qi_2017_CVPR,
	author = {Qi, Charles R. and Su, Hao and Mo, Kaichun and Guibas, Leonidas J.},
	title = {PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {July},
	year = {2017}
}

@article{Wang_2019,
	author = {Wang, Yue and Sun, Yongbin and Liu, Ziwei and Sarma, Sanjay E. and Bronstein, Michael M. and Solomon, Justin M.},
	title = {Dynamic Graph CNN for Learning on Point Clouds},
	year = {2019},
	issue_date = {October 2019},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {38},
	number = {5},
	issn = {0730-0301},
	url = {https://doi.org/10.1145/3326362},
	doi = {10.1145/3326362},
	abstract = {Point clouds provide a flexible geometric representation suitable for countless applications in computer graphics; they also comprise the raw output of most 3D data acquisition devices. While hand-designed features on point clouds have long been proposed in graphics and vision, however, the recent overwhelming success of convolutional neural networks (CNNs) for image analysis suggests the value of adapting insight from CNN to the point cloud world. Point clouds inherently lack topological information, so designing a model to recover topology can enrich the representation power of point clouds. To this end, we propose a new neural network module dubbed EdgeConv suitable for CNN-based high-level tasks on point clouds, including classification and segmentation. EdgeConv acts on graphs dynamically computed in each layer of the network. It is differentiable and can be plugged into existing architectures. Compared to existing modules operating in extrinsic space or treating each point independently, EdgeConv has several appealing properties: It incorporates local neighborhood information; it can be stacked applied to learn global shape properties; and in multi-layer systems affinity in feature space captures semantic characteristics over potentially long distances in the original embedding. We show the performance of our model on standard benchmarks, including ModelNet40, ShapeNetPart, and S3DIS.},
	journal = {ACM Trans. Graph.},
	month = {oct},
	articleno = {146},
	numpages = {12},
	keywords = {classification, Point cloud, segmentation}
}

@InProceedings{Zhao_2021_ICCV,
    author    = {Zhao, Hengshuang and Jiang, Li and Jia, Jiaya and Torr, Philip H.S. and Koltun, Vladlen},
    title     = {Point Transformer},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {16259-16268}
}

@inproceedings{ma2022rethinking,
	title={Rethinking Network Design and Local Geometry in Point Cloud: A Simple Residual {MLP} Framework},
	author={Xu Ma and Can Qin and Haoxuan You and Haoxi Ran and Yun Fu},
	booktitle={International Conference on Learning Representations},
	year={2022},
	url={https://openreview.net/forum?id=3Pbra-_u76D}
}

@inproceedings{Hamilton_2017,
	author = {Hamilton, Will and Ying, Zhitao and Leskovec, Jure},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Inductive Representation Learning on Large Graphs},
	url = {https://proceedings.neurips.cc/paper/2017/file/5dd9db5e033da9c6fb5ba83c7a7ebea9-Paper.pdf},
	volume = {30},
	year = {2017}
}

@article{Partel_2021,
	author = {Partel, Gabriele and WÃ¤hlby, Carolina},
	title = {Spage2vec: Unsupervised representation of localized spatial gene expression signatures},
	journal = {The FEBS Journal},
	volume = {288},
	number = {6},
	pages = {1859-1870},
	keywords = {gene expression, graph representation learning, RNA profiling, spatial transcriptomics, tissue analysis},
	doi = {https://doi.org/10.1111/febs.15572},
	url = {https://febs.onlinelibrary.wiley.com/doi/abs/10.1111/febs.15572},
	eprint = {https://febs.onlinelibrary.wiley.com/doi/pdf/10.1111/febs.15572},
	abstract = {Spatial investigation of cellular heterogeneity is essential to understand tissue organization and function. We present spage2vec, an unsupervised segmentation-free approach for analyzing the spatial transcriptomic landscape at subcellular resolution. Spage2vec models the spatial gene expression as a graph and extracts localized gene expression signatures involved in cellular and subcellular biological processes.},
	year = {2021}
}

@InProceedings{Xiang_2021_ICCV,
    author    = {Xiang, Tiange and Zhang, Chaoyi and Song, Yang and Yu, Jianhui and Cai, Weidong},
    title     = {Walk in the Cloud: Learning Curves for Point Clouds Shape Analysis},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {915-924}
}

@inproceedings{Qi_2017,
	author = {Qi, Charles Ruizhongtai and Yi, Li and Su, Hao and Guibas, Leonidas J},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space},
	url = {https://proceedings.neurips.cc/paper/2017/file/d8bf84be3800d12f74d8b05e9b89836f-Paper.pdf},
	volume = {30},
	year = {2017}
}

@inproceedings{Li_2018,
	author = {Li, Yangyan and Bu, Rui and Sun, Mingchao and Wu, Wei and Di, Xinhan and Chen, Baoquan},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {PointCNN: Convolution On X-Transformed Points},
	url = {https://proceedings.neurips.cc/paper/2018/file/f5f8590cd58a54e94377e6ae2eded4d9-Paper.pdf},
	volume = {31},
	year = {2018}
}

@INPROCEEDINGS{Maturana_2015,
	author={Maturana, Daniel and Scherer, Sebastian},
	booktitle={2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
	title={VoxNet: A 3D Convolutional Neural Network for real-time object recognition},
	year={2015},
	pages={922-928},
	doi={10.1109/IROS.2015.7353481}
}

@InProceedings{Thomas_2019_ICCV,
	author = {Thomas, Hugues and Qi, Charles R. and Deschaud, Jean-Emmanuel and Marcotegui, Beatriz and Goulette, Francois and Guibas, Leonidas J.},
	title = {KPConv: Flexible and Deformable Convolution for Point Clouds},
	booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
	month = {October},
	year = {2019}
}

@InProceedings{Wu_2019_CVPR,
	author = {Wu, Wenxuan and Qi, Zhongang and Fuxin, Li},
	title = {PointConv: Deep Convolutional Networks on 3D Point Clouds},
	booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2019}
}

@inproceedings{Zaheer_2017,
	author = {Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Russ R and Smola, Alexander J},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Deep Sets},
	url = {https://proceedings.neurips.cc/paper/2017/file/f22e4747da1aa27e363d86d40ff442fe-Paper.pdf},
	volume = {30},
	year = {2017}
}

@article{Savulescu_2021,
	title = {Prediction of RNA subcellular localization: Learning from heterogeneous data sources},
	journal = {iScience},
	volume = {24},
	number = {11},
	pages = {103298},
	year = {2021},
	issn = {2589-0042},
	doi = {https://doi.org/10.1016/j.isci.2021.103298},
	url = {https://www.sciencedirect.com/science/article/pii/S2589004221012670},
	author = {Anca Flavia Savulescu and Emmanuel Bouilhol and Nicolas Beaume and Macha Nikolski},
	keywords = {Cell biology, Transcriptomics, Machine learning},
	abstract = {Summary RNA subcellular localization has recently emerged as a widespread phenomenon, which may apply to the majority of RNAs. The two main sources of data for characterization of RNA localization are sequence features and microscopy images, such as obtained from single-molecule fluorescent inÂ situ hybridization-based techniques. Although such imaging data are ideal for characterization of RNA distribution, these techniques remain costly, time-consuming, and technically challenging. Given these limitations, imaging data exist only for a limited number of RNAs. We argue that the field of RNA localization would greatly benefit from complementary techniques able to characterize location of RNA. Here we discuss the importance of RNA localization and the current methodology in the field, followed by an introduction on prediction of location of molecules. We then suggest a machine learning approach based on the integration between imaging localization data and sequence-based data to assist in characterization of RNA localization on a transcriptome level.}
}

@INPROCEEDINGS{Lowe_1999,
	author={Lowe, D.G.},
	booktitle={Proceedings of the Seventh IEEE International Conference on Computer Vision},
	title={Object recognition from local scale-invariant features},
	year={1999},
	volume={2},
	pages={1150-1157 vol.2},
	doi={10.1109/ICCV.1999.790410}
}

@InProceedings{Bay_2006,
	author="Bay, Herbert
	and Tuytelaars, Tinne
	and Van Gool, Luc",
	editor="Leonardis, Ale{\v{s}}
	and Bischof, Horst
	and Pinz, Axel",
	title="SURF: Speeded Up Robust Features",
	booktitle="Computer Vision -- ECCV 2006",
	year="2006",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="404--417",
	abstract="In this paper, we present a novel scale- and rotation-invariant interest point detector and descriptor, coined SURF (Speeded Up Robust Features). It approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster.",
	isbn="978-3-540-33833-8"
}

@InProceedings{Huang_2017_CVPR,
	author = {Huang, Gao and Liu, Zhuang and van der Maaten, Laurens and Weinberger, Kilian Q.},
	title = {Densely Connected Convolutional Networks},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {July},
	year = {2017}
}

@InProceedings{Tan_2019,
  title = 	 {{E}fficient{N}et: Rethinking Model Scaling for Convolutional Neural Networks},
  author =       {Tan, Mingxing and Le, Quoc},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {6105--6114},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/tan19a/tan19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/tan19a.html},
  abstract = 	 {Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are given. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on MobileNets and ResNet. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves stateof-the-art 84.4% top-1 / 97.1% top-5 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet (Huang et al., 2018). Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flower (98.8%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters.}
}

@InProceedings{Szegedy_2016_CVPR,
	author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
	title = {Rethinking the Inception Architecture for Computer Vision},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2016}
}

@InProceedings{He_2016_CVPR,
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	title = {Deep Residual Learning for Image Recognition},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2016}
}

@misc{Mikolov_2013,
  doi = {10.48550/ARXIV.1301.3781},
  url = {https://arxiv.org/abs/1301.3781},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Efficient Estimation of Word Representations in Vector Space},
  publisher = {arXiv},
  year = {2013},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{Joulin_2016,
  doi = {10.48550/ARXIV.1607.01759},
  url = {https://arxiv.org/abs/1607.01759},
  author = {Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Mikolov, Tomas},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Bag of Tricks for Efficient Text Classification},
  publisher = {arXiv},
  year = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{Pennington_2014,
    title = "{G}lo{V}e: Global Vectors for Word Representation",
    author = "Pennington, Jeffrey  and
      Socher, Richard  and
      Manning, Christopher",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D14-1162",
    doi = "10.3115/v1/D14-1162",
    pages = "1532--1543",
}

@article{boland_automated_1998,
	title = {Automated recognition of patterns characteristic of subcellular structures in fluorescence microscopy images},
	volume = {33},
	issn = {0196-4763},
	abstract = {Methods for numerical description and subsequent classification of cellular protein localization patterns are described. Images representing the localization patterns of 4 proteins and DNA were obtained using fluorescence microscopy and divided into distinct training and test sets. The images were processed to remove out-of-focus and background fluorescence and 2 sets of numeric features were generated: Zernike moments and Haralick texture features. These feature sets were used as inputs to either a classification tree or a neural network. Classifier performance (the average percent of each type of image correctly classified) on previously unseen images ranged from 63\% for a classification tree using Zernike moments to 88\% for a backpropagation neural network using a combination of features from the 2 feature sets. These results demonstrate the feasibility of applying pattern recognition methods to subcellular localization patterns, enabling sets of previously unseen images from a single class to be classified with an expected accuracy greater than 99\%. This will provide not only a new automated way to describe proteins, based on localization rather than sequence, but also has potential application in the automation of microscope functions and in the field of gene discovery.},
	language = {eng},
	number = {3},
	journal = {Cytometry},
	author = {Boland, M. V. and Markey, M. K. and Murphy, R. F.},
	month = nov,
	year = {1998},
	pmid = {9822349},
	keywords = {Image Enhancement, Image Processing, Computer-Assisted, Microscopy, Fluorescence, Pattern Recognition, Automated, Proteins},
	pages = {366--375},
}

@article{ouyang_analysis_2019,
	title = {Analysis of the {Human} {Protein} {Atlas} {Image} {Classification} competition},
	volume = {16},
	copyright = {2019 The Author(s)},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-019-0658-6},
	doi = {10.1038/s41592-019-0658-6},
	abstract = {Pinpointing subcellular protein localizations from microscopy images is easy to the trained eye, but challenging to automate. Based on the Human Protein Atlas image collection, we held a competition to identify deep learning solutions to solve this task. Challenges included training on highly imbalanced classes and predicting multiple labels per image. Over 3âmonths, 2,172 teams participated. Despite convergence on popular networks and training techniques, there was considerable variety among the solutions. Participants applied strategies for modifying neural networks and loss functions, augmenting data and using pretrained networks. The winning models far outperformed our previous effort at multi-label classification of protein localization patterns by {\textasciitilde}20\%. These models can be used as classifiers to annotate new images, feature extractors to measure pattern similarity or pretrained networks for a wide range of biological applications.},
	language = {en},
	number = {12},
	urldate = {2022-07-02},
	journal = {Nature Methods},
	author = {Ouyang, Wei and Winsnes, Casper F. and Hjelmare, Martin and Cesnik, Anthony J. and Ãkesson, Lovisa and Xu, Hao and Sullivan, Devin P. and Dai, Shubin and Lan, Jun and Jinmo, Park and Galib, Shaikat M. and Henkel, Christof and Hwang, Kevin and Poplavskiy, Dmytro and Tunguz, Bojan and Wolfinger, Russel D. and Gu, Yinzheng and Li, Chuanpeng and Xie, Jinbin and Buslov, Dmitry and Fironov, Sergei and Kiselev, Alexander and Panchenko, Dmytro and Cao, Xuan and Wei, Runmin and Wu, Yuanhao and Zhu, Xun and Tseng, Kuan-Lun and Gao, Zhifeng and Ju, Cheng and Yi, Xiaohan and Zheng, Hongdong and Kappel, Constantin and Lundberg, Emma},
	month = dec,
	year = {2019},
	keywords = {Image processing, Machine learning, Organelles},
	pages = {1254--1261},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/TJ2RGH3D/Ouyang et al. - 2019 - Analysis of the Human Protein Atlas Image Classifi.pdf:application/pdf},
}

@article{sullivan_deep_2018,
	title = {Deep learning is combined with massive-scale citizen science to improve large-scale image classification},
	volume = {36},
	copyright = {2018 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1546-1696},
	url = {https://www.nature.com/articles/nbt.4225},
	doi = {10.1038/nbt.4225},
	abstract = {Pattern recognition in imaging data by {\textgreater}300,000 players of a global, online, commercial computer game is combined with deep learning to improve the accuracy of annotation of subcellular protein localization.},
	language = {en},
	number = {9},
	urldate = {2022-07-02},
	journal = {Nature Biotechnology},
	author = {Sullivan, Devin P. and Winsnes, Casper F. and Ãkesson, Lovisa and Hjelmare, Martin and Wiking, Mikaela and Schutten, Rutger and Campbell, Linzi and Leifsson, Hjalti and Rhodes, Scott and Nordgren, Andie and Smith, Kevin and Revaz, Bernard and Finnbogason, Bergur and Szantner, Attila and Lundberg, Emma},
	month = oct,
	year = {2018},
	keywords = {Biotechnology, Cell biology, Computational biology and bioinformatics, Scientific community},
	pages = {820--828},
	file = {Full Text:/Users/arthur/Zotero/storage/I4WI2AMA/Sullivan et al. - 2018 - Deep learning is combined with massive-scale citiz.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/HMCCAPLV/nbt.html:text/html},
}

@inproceedings{Grover_2016,
	author = {Grover, Aditya and Leskovec, Jure},
	title = {Node2vec: Scalable Feature Learning for Networks},
	year = {2016},
	isbn = {9781450342322},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2939672.2939754},
	doi = {10.1145/2939672.2939754},
	abstract = {Prediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node's network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations.We demonstrate the efficacy of node2vec over existing state-of-the-art techniques on multi-label classification and link prediction in several real-world networks from diverse domains. Taken together, our work represents a new way for efficiently learning state-of-the-art task-independent representations in complex networks.},
	booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {855â864},
	numpages = {10},
	keywords = {graph representations, feature learning, node embeddings, information networks},
	location = {San Francisco, California, USA},
	series = {KDD '16}
}

@article{Uhlen_2015,
	author = {Mathias UhlÃ©n  and Linn Fagerberg  and BjÃ¶rn M. HallstrÃ¶m  and Cecilia Lindskog  and Per Oksvold  and Adil Mardinoglu  and Ãsa Sivertsson  and Caroline Kampf  and Evelina SjÃ¶stedt  and Anna Asplund  and IngMarie Olsson  and Karolina Edlund  and Emma Lundberg  and Sanjay Navani  and Cristina Al-Khalili Szigyarto  and Jacob Odeberg  and Dijana Djureinovic  and Jenny Ottosson Takanen  and Sophia Hober  and Tove Alm  and Per-Henrik Edqvist  and Holger Berling  and Hanna Tegel  and Jan Mulder  and Johan Rockberg  and Peter Nilsson  and Jochen M. Schwenk  and Marica Hamsten  and Kalle von Feilitzen  and Mattias Forsberg  and Lukas Persson  and Fredric Johansson  and Martin Zwahlen  and Gunnar von Heijne  and Jens Nielsen  and Fredrik PontÃ©n },
	title = {Tissue-based map of the human proteome},
	journal = {Science},
	volume = {347},
	number = {6220},
	pages = {1260419},
	year = {2015},
	doi = {10.1126/science.1260419},
	URL = {https://www.science.org/doi/abs/10.1126/science.1260419},
	eprint = {https://www.science.org/doi/pdf/10.1126/science.1260419},
	abstract = {Sequencing the human genome gave new insights into human biology and disease. However, the ultimate goal is to understand the dynamic expression of each of the approximately 20,000 protein-coding genes and the function of each protein. UhlÃ©n et al. now present a map of protein expression across 32 human tissues. They not only measured expression at an RNA level, but also used antibody profiling to precisely localize the corresponding proteins. An interactive website allows exploration of expression patterns across the human body. Science, this issue 10.1126/science.1260419 Transcriptomics and immunohistochemistry map protein expression across 32 human tissues. Resolving the molecular details of proteome variation in the different tissues and organs of the human body will greatly increase our knowledge of human biology and disease. Here, we present a map of the human tissue proteome based on an integrated omics approach that involves quantitative transcriptomics at the tissue and organ level, combined with tissue microarrayâbased immunohistochemistry, to achieve spatial localization of proteins down to the single-cell level. Our tissue-based analysis detected more than 90\% of the putative protein-coding genes. We used this approach to explore the human secretome, the membrane proteome, the druggable proteome, the cancer proteome, and the metabolic functions in 32 different tissues and organs. All the data are integrated in an interactive Web-based database that allows exploration of individual proteins, as well as navigation of global expression patterns, in all major tissues and organs in the human body.}
}


