@ARTICLE{ahonen_2006,
  author={Ahonen, T. and Hadid, A. and Pietikainen, M.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Face Description with Local Binary Patterns: Application to Face Recognition}, 
  year={2006},
  volume={28},
  number={12},
  pages={2037-2041},
  doi={10.1109/TPAMI.2006.244}}



@article{Wang2008,
	title = {Cellular phenotype recognition for high-content {RNA} interference genome-wide screening.},
	volume = {13},
	issn = {1087-0571},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/18227224},
	doi = {10.1177/1087057107311223},
	abstract = {Genome-wide, cell-based screens using high-content screening (HCS) techniques and automated fluorescence microscopy generate thousands of high-content images that contain an enormous wealth of cell biological information. Such screens are key to the analysis of basic cell biological principles, such as control of cell cycle and cell morphology. However, these screens will ultimately only shed light on human disease mechanisms and potential cures if the analysis can keep up with the generation of data. A fundamental step toward automated analysis of high-content screening is to construct a robust platform for automatic cellular phenotype identification. The authors present a framework, consisting of microscopic image segmentation and analysis components, for automatic recognition of cellular phenotypes in the context of the Rho family of small GTPases. To implicate genes involved in Rac signaling, RNA interference (RNAi) was used to perturb gene functions, and the corresponding cellular phenotypes were analyzed for changes. The data used in the experiments are high-content, 3-channel, fluorescence microscopy images of Drosophila Kc167 cultured cells stained with markers that allow visualization of DNA, polymerized actin filaments, and the constitutively activated Rho protein Rac(V12). The performance of this approach was tested using a cellular database that contained more than 1000 samples of 3 predefined cellular phenotypes, and the generalization error was estimated using a cross-validation technique. Moreover, the authors applied this approach to analyze the whole high-content fluorescence images of Drosophila cells for further HCS-based gene function analysis.},
	number = {1},
	urldate = {2013-01-08},
	journal = {Journal of biomolecular screening},
	author = {Wang, Jun and Zhou, Xiaobo and Bradley, Pamela L and Chang, Shih-Fu and Perrimon, Norbert and Wong, Stephen T C},
	month = jan,
	year = {2008},
	pmid = {18227224},
	keywords = {Animals, Microscopy, Fluorescence, Phenotype, RNA Interference, Genomics, Genomics: methods, Drosophila, Drosophila: genetics, Cell Line, Cytoskeleton, Signal Transduction, Algorithms, Drosophila Proteins, Drosophila Proteins: genetics, Drosophila Proteins: metabolism, Cytoskeleton: ultrastructure, Cell Shape, Cytoskeleton: enzymology, Drosophila Proteins: antagonists \& inhibitors, Drosophila: cytology, Drosophila: enzymology, Genomics: statistics \& numerical data, rac GTP-Binding Proteins, rac GTP-Binding Proteins: antagonists \& inhibitors, rac GTP-Binding Proteins: genetics, rac GTP-Binding Proteins: metabolism, Signal Transduction: genetics, High-content screening, Microscopic image segmentation, Phenotype classification, Phenotype feature extraction and selection, RNA interference},
	pages = {29--39},
}

@article{Uhlmann2016,
	title = {{CP}-{CHARM}: {Segmentation}-free image classification made accessible},
	volume = {17},
	issn = {14712105},
	url = {http://dx.doi.org/10.1186/s12859-016-0895-y},
	doi = {10.1186/s12859-016-0895-y},
	abstract = {BACKGROUND: Automated classification using machine learning often relies on features derived from segmenting individual objects, which can be difficult to automate. WND-CHARM is a previously developed classification algorithm in which features are computed on the whole image, thereby avoiding the need for segmentation. The algorithm obtained encouraging results but requires considerable computational expertise to execute. Furthermore, some benchmark sets have been shown to be subject to confounding artifacts that overestimate classification accuracy.{\textbackslash}n{\textbackslash}nRESULTS: We developed CP-CHARM, a user-friendly image-based classification algorithm inspired by WND-CHARM in (i) its ability to capture a wide variety of morphological aspects of the image, and (ii) the absence of requirement for segmentation. In order to make such an image-based classification method easily accessible to the biological research community, CP-CHARM relies on the widely-used open-source image analysis software CellProfiler for feature extraction. To validate our method, we reproduced WND-CHARM's results and ensured that CP-CHARM obtained comparable performance. We then successfully applied our approach on cell-based assay data and on tissue images. We designed these new training and test sets to reduce the effect of batch-related artifacts.{\textbackslash}n{\textbackslash}nCONCLUSIONS: The proposed method preserves the strengths of WND-CHARM - it extracts a wide variety of morphological features directly on whole images thereby avoiding the need for cell segmentation, but additionally, it makes the methods easily accessible for researchers without computational expertise by implementing them as a CellProfiler pipeline. It has been demonstrated to perform well on a wide range of bioimage classification problems, including on new datasets that have been carefully selected and annotated to minimize batch effects. This provides for the first time a realistic and reliable assessment of the whole image classification strategy.},
	number = {1},
	journal = {BMC Bioinformatics},
	author = {Uhlmann, Virginie and Singh, Shantanu and Carpenter, Anne E.},
	year = {2016},
	pmid = {26817459},
	note = {Publisher: BMC Bioinformatics
ISBN: 14712105 (Electronic)},
	keywords = {Biological imaging, High-dimensional classification, Image classification, Image features, Segmentation-free analysis},
	file = {PDF:/Users/twalter/Zotero/storage/FGU4RJY3/Uhlmann, Singh, Carpenter - 2016 - CP-CHARM Segmentation-free image classification made accessible.pdf:application/pdf},
}

@article{Boland1998,
	title = {Automated recognition of patterns characteristic of subcellular structures in fluorescence microscopy images},
	volume = {33},
	issn = {01964763},
	doi = {10.1002/(SICI)1097-0320(19981101)33:3<366::AID-CYTO12>3.0.CO;2-R},
	abstract = {Methods for numerical description and subsequent classification of cellular protein localization patterns are described. Images representing the localization patterns of 4 proteins and DNA were obtained using fluorescence microscopy and divided into distinct training and test sets. The images were processed to remove out-of-focus and background fluorescence and 2 sets of numeric features were generated: Zernike moments and Haralick texture features. These feature sets were used as inputs to either a classification tree or a neural network. Classifier performance (the average percent of each type of image correctly classified) on previously unseen images ranged from 63\% for a classification tree using Zernike moments to 88\% for a backpropagation neural network using a combination of features from the 2 feature sets. These results demonstrate the feasibility of applying pattern recognition methods to subcellular localization patterns, enabling sets of previously unseen images from a single class to be classified with an expected accuracy greater than 99\%. This will provide not only a new automated way to describe proteins, based on localization rather than sequence, but also has potential application in the automation of microscope functions and in the field of gene discovery.},
	journal = {Cytometry},
	author = {Boland, Michael V. and Markey, Mia K. and Murphy, Robert F.},
	year = {1998},
	pmid = {9822349},
	note = {ISBN: 0196-4763},
	keywords = {Microscopy, Fluorescence, Neural networks (computer), Pattern recognition, Protein localization, Subcellular location, Zernike moments},
	pages = {366--375},
}


@article{Carpenter2006,
	title = {{CellProfiler}: image analysis software for identifying and quantifying cell phenotypes.},
	volume = {7},
	issn = {1465-6914},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1794559&tool=pmcentrez&rendertype=abstract},
	doi = {10.1186/gb-2006-7-10-r100},
	abstract = {Biologists can now prepare and image thousands of samples per day using automation, enabling chemical screens and functional genomics (for example, using RNA interference). Here we describe the first free, open-source system designed for flexible, high-throughput cell image analysis, CellProfiler. CellProfiler can address a variety of biological questions quantitatively, including standard assays (for example, cell count, size, per-cell protein levels) and complex morphological assays (for example, cell/organelle shape or subcellular patterns of DNA or protein staining).},
	number = {10},
	urldate = {2012-11-04},
	journal = {Genome biology},
	author = {Carpenter, Anne E and Jones, Thouis R and Lamprecht, Michael R and Clarke, Colin and Kang, In Han and Friman, Ola and Guertin, David a and Chang, Joo Han and Lindquist, Robert a and Moffat, Jason and Golland, Polina and Sabatini, David M},
	month = jan,
	year = {2006},
	pmid = {17076895},
	keywords = {Software, Image Processing, Computer-Assisted, Phenotype, Reproducibility of Results, Models, Genetic, Gene Expression Profiling, Dose-Response Relationship, Drug, Mutation},
	pages = {R100},
	file = {PDF:/Users/twalter/Zotero/storage/T93BUPLQ/Carpenter et al. - 2006 - CellProfiler image analysis software for identifying and quantifying cell phenotypes.pdf:application/pdf},
}


@article{Levet2019,
	title = {A tessellation-based colocalization analysis approach for single-molecule localization microscopy},
	volume = {10},
	issn = {2041-1723},
	url = {http://www.nature.com/articles/s41467-019-10007-4},
	doi = {10.1038/s41467-019-10007-4},
	language = {en},
	number = {1},
	urldate = {2022-11-09},
	journal = {Nature Communications},
	author = {Levet, Florian and Julien, Guillaume and Galland, Rémi and Butler, Corey and Beghin, Anne and Chazeau, Anaël and Hoess, Philipp and Ries, Jonas and Giannone, Grégory and Sibarita, Jean-Baptiste},
	month = dec,
	year = {2019},
	pages = {2379},
	file = {Levet et al. - 2019 - A tessellation-based colocalization analysis appro.pdf:/Users/twalter/Zotero/storage/VWZTPQA3/Levet et al. - 2019 - A tessellation-based colocalization analysis appro.pdf:application/pdf},
}

@article{Ouyang2019b,
	title = {Analysis of the {Human} {Protein} {Atlas} {Image} {Classification} competition},
	volume = {16},
	issn = {1548-7091, 1548-7105},
	url = {http://www.nature.com/articles/s41592-019-0658-6},
	doi = {10.1038/s41592-019-0658-6},
	abstract = {Abstract
            Pinpointing subcellular protein localizations from microscopy images is easy to the trained eye, but challenging to automate. Based on the Human Protein Atlas image collection, we held a competition to identify deep learning solutions to solve this task. Challenges included training on highly imbalanced classes and predicting multiple labels per image. Over 3 months, 2,172 teams participated. Despite convergence on popular networks and training techniques, there was considerable variety among the solutions. Participants applied strategies for modifying neural networks and loss functions, augmenting data and using pretrained networks. The winning models far outperformed our previous effort at multi-label classification of protein localization patterns by {\textasciitilde}20\%. These models can be used as classifiers to annotate new images, feature extractors to measure pattern similarity or pretrained networks for a wide range of biological applications.},
	language = {en},
	number = {12},
	urldate = {2021-02-04},
	journal = {Nature Methods},
	author = {Ouyang, Wei and Winsnes, Casper F. and Hjelmare, Martin and Cesnik, Anthony J. and Åkesson, Lovisa and Xu, Hao and Sullivan, Devin P. and Dai, Shubin and Lan, Jun and Jinmo, Park and Galib, Shaikat M. and Henkel, Christof and Hwang, Kevin and Poplavskiy, Dmytro and Tunguz, Bojan and Wolfinger, Russel D. and Gu, Yinzheng and Li, Chuanpeng and Xie, Jinbin and Buslov, Dmitry and Fironov, Sergei and Kiselev, Alexander and Panchenko, Dmytro and Cao, Xuan and Wei, Runmin and Wu, Yuanhao and Zhu, Xun and Tseng, Kuan-Lun and Gao, Zhifeng and Ju, Cheng and Yi, Xiaohan and Zheng, Hongdong and Kappel, Constantin and Lundberg, Emma},
	month = dec,
	year = {2019},
	pages = {1254--1261},
	file = {Ouyang et al. - 2019 - Analysis of the Human Protein Atlas Image Classifi.pdf:/Users/twalter/Zotero/storage/ZCWGP3L7/Ouyang et al. - 2019 - Analysis of the Human Protein Atlas Image Classifi.pdf:application/pdf},
}

@article{mahotas_2013,
	title = {Mahotas: {Open} source software for scriptable computer vision},
	volume = {1},
	issn = {2049-9647},
	shorttitle = {Mahotas},
	url = {http://openresearchsoftware.metajnl.com/articles/10.5334/jors.ac/},
	doi = {10.5334/jors.ac},
	abstract = {Mahotas is a computer vision library for Python. It contains traditional image processing functionality such as filtering and morphological operations as well as more modern computer vision functions for feature computation, including interest point detection and local descriptors. The interface is in Python, a dynamic programming language, which is appropriate for fast development, but the algorithms are implemented in C++ and are tuned for speed. The library is designed to fit in with the scientific software ecosystem in this language and can leverage the existing infrastructure developed in that language. Mahotas is released under a liberal open source license (MIT License) and is available from http:// github.com/luispedro/mahotas and from the Python Package Index (http://pypi.python.org/pypi/mahotas). Tutorials and full API documentation are available online at http://mahotas.readthedocs.org/.},
	language = {en},
	number = {1},
	urldate = {2022-11-08},
	journal = {Journal of Open Research Software},
	month = jul,
	year = {2013},
	pages = {e3},
	file = {2013 - Mahotas Open source software for scriptable compu.pdf:/Users/twalter/Zotero/storage/L9WVDF2C/2013 - Mahotas Open source software for scriptable compu.pdf:application/pdf},
}

@article{Jones2009,
	title = {Scoring diverse cellular morphologies in image-based screens with iterative feedback and machine learning.},
	volume = {106},
	issn = {1091-6490},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2634799&tool=pmcentrez&rendertype=abstract},
	doi = {10.1073/pnas.0808843106},
	abstract = {Many biological pathways were first uncovered by identifying mutants with visible phenotypes and by scoring every sample in a screen via tedious and subjective visual inspection. Now, automated image analysis can effectively score many phenotypes. In practical application, customizing an image-analysis algorithm or finding a sufficient number of example cells to train a machine learning algorithm can be infeasible, particularly when positive control samples are not available and the phenotype of interest is rare. Here we present a supervised machine learning approach that uses iterative feedback to readily score multiple subtle and complex morphological phenotypes in high-throughput, image-based screens. First, automated cytological profiling extracts hundreds of numerical descriptors for every cell in every image. Next, the researcher generates a rule (i.e., classifier) to recognize cells with a phenotype of interest during a short, interactive training session using iterative feedback. Finally, all of the cells in the experiment are automatically classified and each sample is scored based on the presence of cells displaying the phenotype. By using this approach, we successfully scored images in RNA interference screens in 2 organisms for the prevalence of 15 diverse cellular morphologies, some of which were previously intractable.},
	number = {6},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Jones, Thouis R and Carpenter, Anne E and Lamprecht, Michael R and Moffat, Jason and Silver, Serena J and Grenier, Jennifer K and Castoreno, Adam B and Eggert, Ulrike S and Root, David E and Golland, Polina and Sabatini, David M},
	month = feb,
	year = {2009},
	pmid = {19188593},
	keywords = {Animals, Cells, Cells: cytology, Humans, Phenotype, RNA Interference, Computer-Assisted, Algorithms, Artificial Intelligence, Cells: ultrastructure, Tissue Array Analysis, Image Cytometry, Image Cytometry: methods, Diagnostic Imaging, Automated, Automated: methods, Cells: chemistry, Computer-Assisted: methods, Diagnostic Imaging: methods, Feedback, Image Interpretation, Pattern Recognition},
	pages = {1826--31},
}

@article{Jones2008,
	title = {{CellProfiler} {Analyst}: data exploration and analysis software for complex image-based screens.},
	volume = {9},
	issn = {1471-2105},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2614436&tool=pmcentrez&rendertype=abstract},
	doi = {10.1186/1471-2105-9-482},
	abstract = {Image-based screens can produce hundreds of measured features for each of hundreds of millions of individual cells in a single experiment.},
	urldate = {2012-11-08},
	journal = {BMC bioinformatics},
	author = {Jones, Thouis R and Kang, In Han and Wheeler, Douglas B and Lindquist, Robert a and Papallo, Adam and Sabatini, David M and Golland, Polina and Carpenter, Anne E},
	month = jan,
	year = {2008},
	pmid = {19014601},
	keywords = {Computational Biology, Computational Biology: methods, Software, Cells, Image Processing, Computer-Assisted, Image Processing, Computer-Assisted: methods, Phenotype, Artificial Intelligence, Cells: ultrastructure},
	pages = {482},
	file = {PDF:/Users/twalter/Zotero/storage/BA882FSC/Jones et al. - 2008 - CellProfiler Analyst data exploration and analysis software for complex image-based screens.pdf:application/pdf},
}

@article{Walter2010,
	title = {Automatic identification and clustering of chromosome phenotypes in a genome wide {RNAi} screen by time-lapse imaging.},
	volume = {170},
	issn = {1095-8657},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/19854275},
	doi = {10.1016/j.jsb.2009.10.004},
	abstract = {High-throughput time-lapse microscopy is an excellent way of studying gene function by collecting time-resolved image data of the cellular responses to gene perturbations. With the increase in both data amount and complexity, computational methods capable of dealing with large image data sets are required. While image processing methods have been successfully applied to endpoint assays in the past, the analysis of complex time-resolved read-outs was so far still too immature to be applied on a large-scale. Here, we present a complete computational processing pipeline for such screens. By automatic image processing and machine learning, a quantitative description of phenotypic dynamics is obtained from the raw bitmaps. In order to visualize the resulting phenotypes in their temporal context, we introduce Event Order Maps allowing a concise representation of the major tendencies of causes and consequences of phenotypic classes. In order to cluster the phenotypic kinetics, we propose a novel technique based on trajectory representation of multidimensional time series. We demonstrate the use of these methods applying them on a genome wide RNAi screen by time-lapse microscopy.},
	number = {1},
	urldate = {2012-11-08},
	journal = {Journal of structural biology},
	author = {Walter, Thomas and Held, Michael and Neumann, Beate and Hériché, Jean-Karim and Conrad, Christian and Pepperkok, Rainer and Ellenberg, Jan},
	month = apr,
	year = {2010},
	pmid = {19854275},
	note = {Publisher: Elsevier Inc.},
	keywords = {Computational Biology, Computational Biology: methods, Software, Humans, Time Factors, Phenotype, RNA Interference, Proteomics, Proteomics: methods, Gene Expression Profiling, HeLa Cells, Gene Expression Profiling: methods, Computer-Assisted, Image Processing, Artificial Intelligence, Computer-Assisted: methods},
	pages = {1--9},
	file = {PDF:/Users/twalter/Zotero/storage/N3ZRQBS7/Walter et al. - 2010 - Automatic identification and clustering of chromosome phenotypes in a genome wide RNAi screen by time-lapse imagi.pdf:application/pdf},
}

@article{Glory2007,
	title = {Automated subcellular location determination and high-throughput microscopy.},
	volume = {12},
	issn = {1534-5807},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/17199037},
	doi = {10.1016/j.devcel.2006.12.007},
	number = {1},
	urldate = {2012-11-09},
	journal = {Developmental cell},
	author = {Glory, Estelle and Murphy, Robert F},
	month = jan,
	year = {2007},
	pmid = {17199037},
	keywords = {Databases, Factual, Animals, Automation, Automation: methods, Cells, Cells: cytology, Cells: metabolism, Humans, Microscopy, Fluorescence, Microscopy, Fluorescence: methods, Protein Transport, Time Factors},
	pages = {7--16},
}

@article{Coelho2010,
	title = {Principles of bioimage informatics: {Focus} on machine learning of cell patterns},
	volume = {6004 LNBI},
	issn = {03029743},
	doi = {10.1007/978-3-642-13131-8_2},
	abstract = {The field of bioimage informatics concerns the development and use of methods for computational analysis of biological images. Traditionally, analysis of such images has been done manually. Manual annotation is, however, slow, expensive, and often highly variable from one expert to another. Furthermore, with modern automated microscopes, hundreds to thousands of images can be collected per hour, making manual analysis infeasible. This field borrows from the pattern recognition and computer vision literature (which contain many techniques for image processing and recognition), but has its own unique challenges and tradeoffs. Fluorescence microscopy images represent perhaps the largest class of biological images for which automation is needed. For this modality, typical problems include cell segmentation, classification of phenotypical response, or decisions regarding differentiated responses (treatment vs. control setting). This overview focuses on the problem of subcellular location determination as a running example, but the techniques discussed are often applicable to other problems.},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Coelho, Luis Pedro and Glory-Afshar, Estelle and Kangas, Joshua and Quinn, Shannon and Shariff, Aabid and Murphy, Robert F.},
	year = {2010},
	note = {ISBN: 3642131301},
	pages = {8--18},
}


@article{Reeve1992,
	title = {A {Survey} of {Moment}-{Based} {Techniques} {For} {Unoccluded} {Object} {Representation} and {Recognition}},
	journal = {CVGIP: Graphical Models and Image Processing},
	author = {Reeve, Richard J.; and Prokop, Anthony P.;},
	year = {1992},
	pages = {438--460},
}

@article{Uhlmann2016,
	title = {{CP}-{CHARM}: {Segmentation}-free image classification made accessible},
	volume = {17},
	issn = {14712105},
	url = {http://dx.doi.org/10.1186/s12859-016-0895-y},
	doi = {10.1186/s12859-016-0895-y},
	abstract = {BACKGROUND: Automated classification using machine learning often relies on features derived from segmenting individual objects, which can be difficult to automate. WND-CHARM is a previously developed classification algorithm in which features are computed on the whole image, thereby avoiding the need for segmentation. The algorithm obtained encouraging results but requires considerable computational expertise to execute. Furthermore, some benchmark sets have been shown to be subject to confounding artifacts that overestimate classification accuracy.{\textbackslash}n{\textbackslash}nRESULTS: We developed CP-CHARM, a user-friendly image-based classification algorithm inspired by WND-CHARM in (i) its ability to capture a wide variety of morphological aspects of the image, and (ii) the absence of requirement for segmentation. In order to make such an image-based classification method easily accessible to the biological research community, CP-CHARM relies on the widely-used open-source image analysis software CellProfiler for feature extraction. To validate our method, we reproduced WND-CHARM's results and ensured that CP-CHARM obtained comparable performance. We then successfully applied our approach on cell-based assay data and on tissue images. We designed these new training and test sets to reduce the effect of batch-related artifacts.{\textbackslash}n{\textbackslash}nCONCLUSIONS: The proposed method preserves the strengths of WND-CHARM - it extracts a wide variety of morphological features directly on whole images thereby avoiding the need for cell segmentation, but additionally, it makes the methods easily accessible for researchers without computational expertise by implementing them as a CellProfiler pipeline. It has been demonstrated to perform well on a wide range of bioimage classification problems, including on new datasets that have been carefully selected and annotated to minimize batch effects. This provides for the first time a realistic and reliable assessment of the whole image classification strategy.},
	number = {1},
	journal = {BMC Bioinformatics},
	author = {Uhlmann, Virginie and Singh, Shantanu and Carpenter, Anne E.},
	year = {2016},
	pmid = {26817459},
	note = {Publisher: BMC Bioinformatics
ISBN: 14712105 (Electronic)},
	keywords = {Biological imaging, High-dimensional classification, Image classification, Image features, Segmentation-free analysis},
	file = {PDF:/Users/twalter/Zotero/storage/FGU4RJY3/Uhlmann, Singh, Carpenter - 2016 - CP-CHARM Segmentation-free image classification made accessible.pdf:application/pdf},
}

@article{Haralick1973,
  author = {Haralick, R. M. and Dinstein and Shanmugam, K. },
  title = {Textural features for image classification},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics},
  year = {1973},
  volume = {SMC-3},
  pages = {610--621},
  month = {November},
  abstract = {Description of some easily computable textural features based on gray-tone
	spatial dependances, and illustration of their application in category-identification
	tasks of three different kinds of image data - namely, photomicrographs
	of five kinds of sandstones, 1:20,000 panchromatic aerial photographs
	of eight land-use categories, and ERTS multispectral imagery containing
	several land-use categories. Two kinds of decision rules are used
	- one for which the decision regions are convex polyhedra (a piecewise-linear
	decision rule), and one for which the decision regions are rectangular
	parallelpipeds (a min-max decision rule). In each experiment the
	data set was divided into two parts, a training set and a test set.
	Test set identification accuracy is 89\% for the photomicrographs,
	82\% for the aerial photographic imagery, and 83\% for the satellite
	imagery. These results indicate that the easily computable textural
	features probably have a general applicability for a wide variety
	of image-classification applications.},
  citeulike-article-id = {80546},
  keywords = {image-processing, texture, texture-analysis},
  priority = {2},
  url = {\#}
}

@conference{Walker1996,
  author = {Ross F Walker and Paul Jackway},
  title = {Statistical Geometric Features - Extensions for Cytological Texture
	Analysis},
  booktitle = {ICPR - International Conference on Pattern Recognition},
  year = {1996},
  owner = {twalter},
  pdf = {CellImaging/Walker/icpr_Walker1996.pdf},
  timestamp = {2007.08.08}
}

@article{cochard_rna_2022,
	title = {{RNA} at the surface of phase-separated condensates impacts their size and number},
	volume = {121},
	issn = {0006-3495},
	url = {https://www.cell.com/biophysj/abstract/S0006-3495(22)00242-9},
	doi = {10.1016/j.bpj.2022.03.032},
	language = {English},
	number = {9},
	urldate = {2022-06-24},
	journal = {Biophysical Journal},
	author = {Cochard, Audrey and Navarro, Marina Garcia-Jove and Piroska, Leonard and Kashida, Shunnichi and Kress, Michel and Weil, Dominique and Gueroui, Zoher},
	month = may,
	year = {2022},
	pmid = {35364105},
	note = {Publisher: Elsevier},
	pages = {1675--1690}
}

@article{khater_caveolae_2019,
	title = {Caveolae and scaffold detection from single molecule localization microscopy data using deep learning},
	volume = {14},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0211659},
	doi = {10.1371/journal.pone.0211659},
	abstract = {Caveolae are plasma membrane invaginations whose formation requires caveolin-1 (Cav1), the adaptor protein polymerase I, and the transcript release factor (PTRF or CAVIN1). Caveolae have an important role in cell functioning, signaling, and disease. In the absence of CAVIN1/PTRF, Cav1 forms non-caveolar membrane domains called scaffolds. In this work, we train machine learning models to automatically distinguish between caveolae and scaffolds from single molecule localization microscopy (SMLM) data. We apply machine learning algorithms to discriminate biological structures from SMLM data. Our work is the first that is leveraging machine learning approaches (including deep learning models) to automatically identifying biological structures from SMLM data. In particular, we develop and compare three binary classification methods to identify whether or not a given 3D cluster of Cav1 proteins is a caveolae. The first uses a random forest classifier applied to 28 hand-crafted/designed features, the second uses a convolutional neural net (CNN) applied to a projection of the point clouds onto three planes, and the third uses a PointNet model, a recent development that can directly take point clouds as its input. We validate our methods on a dataset of super-resolution microscopy images of PC3 prostate cancer cells labeled for Cav1. Specifically, we have images from two cell populations: 10 PC3 and 10 CAVIN1/PTRF-transfected PC3 cells (PC3-PTRF cells) that form caveolae. We obtained a balanced set of 1714 different cellular structures. Our results show that both the random forest on hand-designed features and the deep learning approach achieve high accuracy in distinguishing the intrinsic features of the caveolae and non-caveolae biological structures. More specifically, both random forest and deep CNN classifiers achieve classification accuracy reaching 94\% on our test set, while the PointNet model only reached 83\% accuracy. We also discuss the pros and cons of the different approaches.},
	language = {en},
	number = {8},
	urldate = {2022-05-17},
	journal = {PLOS ONE},
	author = {Khater, Ismail M. and Aroca-Ouellette, Stephane T. and Meng, Fanrui and Nabi, Ivan Robert and Hamarneh, Ghassan},
	month = aug,
	year = {2019},
	note = {Publisher: Public Library of Science},
	keywords = {Cell membranes, Cellular structures and organelles, Coated pits, Deep learning, Imaging techniques, Machine learning, Membrane proteins, Prostate cancer},
	pages = {e0211659},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/UFXV63EX/Khater et al. - 2019 - Caveolae and scaffold detection from single molecu.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/9YJTQ2ZG/article.html:text/html},
}

@article{savulescu_interrogating_2021,
	title = {Interrogating {RNA} and protein spatial subcellular distribution in {smFISH} data with {DypFISH}},
	volume = {1},
	issn = {2667-2375},
	url = {https://www.sciencedirect.com/science/article/pii/S266723752100120X},
	doi = {10.1016/j.crmeth.2021.100068},
	abstract = {Advances in single-cell RNA sequencing have allowed for the identification of cellular subtypes on the basis of quantification of the number of transcripts in each cell. However, cells might also differ in the spatial distribution of molecules, including RNAs. Here, we present DypFISH, an approach to quantitatively investigate the subcellular localization of RNA and protein. We introduce a range of analytical techniques to interrogate single-molecule RNA fluorescence in situ hybridization (smFISH) data in combination with protein immunolabeling. DypFISH is suited to study patterns of clustering of molecules, the association of mRNA-protein subcellular localization with microtubule organizing center orientation, and interdependence of mRNA-protein spatial distributions. We showcase how our analytical tools can achieve biological insights by utilizing cell micropatterning to constrain cellular architecture, which leads to reduction in subcellular mRNA distribution variation, allowing for the characterization of their localization patterns. Furthermore, we show that our method can be applied to physiological systems such as skeletal muscle fibers.},
	language = {en},
	number = {5},
	urldate = {2022-05-17},
	journal = {Cell Reports Methods},
	author = {Savulescu, Anca F. and Brackin, Robyn and Bouilhol, Emmanuel and Dartigues, Benjamin and Warrell, Jonathan H. and Pimentel, Mafalda R. and Beaume, Nicolas and Fortunato, Isabela C. and Dallongeville, Stephane and Boulle, Mikaël and Soueidan, Hayssam and Agou, Fabrice and Schmoranzer, Jan and Olivo-Marin, Jean-Christophe and Franco, Claudio A. and Gomes, Edgar R. and Nikolski, Macha and Mhlanga, Musa M.},
	month = sep,
	year = {2021},
	keywords = {image analysis, microfabricated patterns, Ripley's K, RNA subcellular localization, single-molecule FISH},
	pages = {100068},
	file = {Full Text:/Users/arthur/Zotero/storage/MQNNAMFZ/Savulescu et al. - 2021 - Interrogating RNA and protein spatial subcellular .pdf:application/pdf;ScienceDirect Snapshot:/Users/arthur/Zotero/storage/MIXSHL38/S266723752100120X.html:text/html},
}

@article{samacoits_computational_2018,
	title = {A computational framework to study sub-cellular {RNA} localization},
	volume = {9},
	copyright = {2018 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-018-06868-w},
	doi = {10.1038/s41467-018-06868-w},
	abstract = {RNA localization is a crucial process for cellular function and can be quantitatively studied by single molecule FISH (smFISH). Here, we present an integrated analysis framework to analyze sub-cellular RNA localization. Using simulated images, we design and validate a set of features describing different RNA localization patterns including polarized distribution, accumulation in cell extensions or foci, at the cell membrane or nuclear envelope. These features are largely invariant to RNA levels, work in multiple cell lines, and can measure localization strength in perturbation experiments. Most importantly, they allow classification by supervised and unsupervised learning at unprecedented accuracy. We successfully validate our approach on representative experimental data. This analysis reveals a surprisingly high degree of localization heterogeneity at the single cell level, indicating a dynamic and plastic nature of RNA localization.},
	language = {en},
	number = {1},
	urldate = {2022-05-17},
	journal = {Nature Communications},
	author = {Samacoits, Aubin and Chouaib, Racha and Safieddine, Adham and Traboulsi, Abdel-Meneem and Ouyang, Wei and Zimmer, Christophe and Peter, Marion and Bertrand, Edouard and Walter, Thomas and Mueller, Florian},
	month = nov,
	year = {2018},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Cellular imaging, Fluorescence imaging, Fluorescence in situ hybridization, Software},
	pages = {4584},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/BGITRCI2/Samacoits et al. - 2018 - A computational framework to study sub-cellular RN.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/8EDHVHMY/s41467-018-06868-w.html:text/html},
}

@article{stoeger_computer_2015,
	series = {Inferring {Gene} {Regulatory} {Interactions} from {Quantitative} {High}-{Throughput} {Measurements}},
	title = {Computer vision for image-based transcriptomics},
	volume = {85},
	issn = {1046-2023},
	url = {https://www.sciencedirect.com/science/article/pii/S1046202315002091},
	doi = {10.1016/j.ymeth.2015.05.016},
	abstract = {Single-cell transcriptomics has recently emerged as one of the most promising tools for understanding the diversity of the transcriptome among single cells. Image-based transcriptomics is unique compared to other methods as it does not require conversion of RNA to cDNA prior to signal amplification and transcript quantification. Thus, its efficiency in transcript detection is unmatched by other methods. In addition, image-based transcriptomics allows the study of the spatial organization of the transcriptome in single cells at single-molecule, and, when combined with superresolution microscopy, nanometer resolution. However, in order to unlock the full power of image-based transcriptomics, robust computer vision of single molecules and cells is required. Here, we shortly discuss the setup of the experimental pipeline for image-based transcriptomics, and then describe in detail the algorithms that we developed to extract, at high-throughput, robust multivariate feature sets of transcript molecule abundance, localization and patterning in tens of thousands of single cells across the transcriptome. These computer vision algorithms and pipelines can be downloaded from: https://github.com/pelkmanslab/ImageBasedTranscriptomics.},
	language = {en},
	urldate = {2021-09-14},
	journal = {Methods},
	author = {Stoeger, Thomas and Battich, Nico and Herrmann, Markus D. and Yakimovich, Yauhen and Pelkmans, Lucas},
	month = sep,
	year = {2015},
	keywords = {FISH, High-throughput, hybridization, Image-based transcriptomics, Localization, Segmentation, Single-cell, Single-molecule, Subcellular},
	pages = {44--53},
	file = {Accepted Version:/Users/arthur/Zotero/storage/NND4A8GY/Stoeger et al. - 2015 - Computer vision for image-based transcriptomics.pdf:application/pdf;ScienceDirect Snapshot:/Users/arthur/Zotero/storage/CE7Y78IB/S1046202315002091.html:text/html},
}

@article{mcquin_cellprofiler_2018,
	title = {{CellProfiler} 3.0: {Next}-generation image processing for biology},
	volume = {16},
	issn = {1545-7885},
	shorttitle = {{CellProfiler} 3.0},
	url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2005970},
	doi = {10.1371/journal.pbio.2005970},
	abstract = {CellProfiler has enabled the scientific research community to create flexible, modular image analysis pipelines since its release in 2005. Here, we describe CellProfiler 3.0, a new version of the software supporting both whole-volume and plane-wise analysis of three-dimensional (3D) image stacks, increasingly common in biomedical research. CellProfiler’s infrastructure is greatly improved, and we provide a protocol for cloud-based, large-scale image processing. New plugins enable running pretrained deep learning models on images. Designed by and for biologists, CellProfiler equips researchers with powerful computational tools via a well-documented user interface, empowering biologists in all fields to create quantitative, reproducible image analysis workflows.},
	language = {en},
	number = {7},
	urldate = {2021-09-13},
	journal = {PLOS Biology},
	author = {McQuin, Claire and Goodman, Allen and Chernyshev, Vasiliy and Kamentsky, Lee and Cimini, Beth A. and Karhohs, Kyle W. and Doan, Minh and Ding, Liya and Rafelski, Susanne M. and Thirstrup, Derek and Wiegraebe, Winfried and Singh, Shantanu and Becker, Tim and Caicedo, Juan C. and Carpenter, Anne E.},
	month = jul,
	year = {2018},
	note = {Publisher: Public Library of Science},
	keywords = {Biologists, Blastocysts, Cell staining, Computer software, Deep learning, Image analysis, Image processing, Open source software},
	pages = {e2005970},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/S8F4J3CM/McQuin et al. - 2018 - CellProfiler 3.0 Next-generation image processing.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/DCPQKCNU/article.html:text/html},
}

@article{held_cellcognition_2010,
	title = {{CellCognition}: time-resolved phenotype annotation in high-throughput live cell imaging},
	volume = {7},
	issn = {1548-7105},
	shorttitle = {{CellCognition}},
	doi = {10.1038/nmeth.1486},
	abstract = {Fluorescence time-lapse imaging has become a powerful tool to investigate complex dynamic processes such as cell division or intracellular trafficking. Automated microscopes generate time-resolved imaging data at high throughput, yet tools for quantification of large-scale movie data are largely missing. Here we present CellCognition, a computational framework to annotate complex cellular dynamics. We developed a machine-learning method that combines state-of-the-art classification with hidden Markov modeling for annotation of the progression through morphologically distinct biological states. Incorporation of time information into the annotation scheme was essential to suppress classification noise at state transitions and confusion between different functional states with similar morphology. We demonstrate generic applicability in different assays and perturbation conditions, including a candidate-based RNA interference screen for regulators of mitotic exit in human cells. CellCognition is published as open source software, enabling live-cell imaging-based screening with assays that directly score cellular dynamics.},
	number = {9},
	journal = {Nature Methods},
	author = {Held, Michael and Schmitz, Michael H. A. and Fischer, Bernd and Walter, Thomas and Neumann, Beate and Olma, Michael H. and Peter, Matthias and Ellenberg, Jan and Gerlich, Daniel W.},
	year = {2010},
	pmid = {20693996},
	keywords = {Artificial Intelligence, Automation, Cell Shape, Cell Survival, Cells, Computational Biology, Computer Simulation, Fluorescence, HeLa Cells, Humans, Image Processing, Computer-Assisted, Kinetics, Markov Chains, Mitosis, Molecular Imaging, Phenotype, Software, Time Factors},
	pages = {747--754}
}

@article{berg_ilastik_2019,
	title = {ilastik: interactive machine learning for (bio)image analysis},
	volume = {16},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	shorttitle = {ilastik},
	url = {https://www.nature.com/articles/s41592-019-0582-9},
	doi = {10.1038/s41592-019-0582-9},
	abstract = {We present ilastik, an easy-to-use interactive tool that brings machine-learning-based (bio)image analysis to end users without substantial computational expertise. It contains pre-defined workflows for image segmentation, object classification, counting and tracking. Users adapt the workflows to the problem at hand by interactively providing sparse training annotations for a nonlinear classifier. ilastik can process data in up to five dimensions (3D, time and number of channels). Its computational back end runs operations on-demand wherever possible, allowing for interactive prediction on data larger than RAM. Once the classifiers are trained, ilastik workflows can be applied to new data from the command line without further user interaction. We describe all ilastik workflows in detail, including three case studies and a discussion on the expected performance.},
	language = {en},
	number = {12},
	urldate = {2021-09-13},
	journal = {Nature Methods},
	author = {Berg, Stuart and Kutra, Dominik and Kroeger, Thorben and Straehle, Christoph N. and Kausler, Bernhard X. and Haubold, Carsten and Schiegg, Martin and Ales, Janez and Beier, Thorsten and Rudy, Markus and Eren, Kemal and Cervantes, Jaime I. and Xu, Buote and Beuttenmueller, Fynn and Wolny, Adrian and Zhang, Chong and Koethe, Ullrich and Hamprecht, Fred A. and Kreshuk, Anna},
	month = dec,
	year = {2019},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Number: 12
Primary\_atype: Reviews
Publisher: Nature Publishing Group
Subject\_term: Image processing;Machine learning;Software
Subject\_term\_id: image-processing;machine-learning;software},
	pages = {1226--1232},
	file = {Snapshot:/Users/arthur/Zotero/storage/P8PQ3T45/s41592-019-0582-9.html:text/html;Submitted Version:/Users/arthur/Zotero/storage/HCJBK3TP/Berg et al. - 2019 - ilastik interactive machine learning for (bio)ima.pdf:application/pdf},
}

@article{shariff_automated_2010,
	title = {Automated {Image} {Analysis} for {High}-{Content} {Screening} and {Analysis}},
	volume = {15},
	issn = {2472-5552, 2472-5560},
	url = {https://slas-discovery.org/article/S2472-5552(22)07949-7/fulltext},
	doi = {10.1177/1087057110370894},
	language = {English},
	number = {7},
	urldate = {2022-05-17},
	journal = {SLAS Discovery},
	author = {Shariff, Aabid and Kangas, Joshua and Coelho, Luis Pedro and Quinn, Shannon and Murphy, Robert F.},
	month = aug,
	year = {2010},
	note = {Publisher: Elsevier},
	keywords = {bioimage informatics, high-content screening, image analysis, machine learning, subcellular location},
	pages = {726--734},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/SMIWB58A/Shariff et al. - 2010 - Automated Image Analysis for High-Content Screenin.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/5NP4SQTV/fulltext.html:text/html},
}

@article{laux_interactive_2020,
	title = {Interactive machine learning for fast and robust cell profiling},
	volume = {15},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0237972},
	doi = {10.1371/journal.pone.0237972},
	abstract = {Automated profiling of cell morphology is a powerful tool for inferring cell function. However, this technique retains a high barrier to entry. In particular, configuring image processing parameters for optimal cell profiling is susceptible to cognitive biases and dependent on user experience. Here, we use interactive machine learning to identify the optimum cell profiling configuration that maximises quality of the cell profiling outcome. The process is guided by the user, from whom a rating of the quality of a cell profiling configuration is obtained. We use Bayesian optimisation, an established machine learning algorithm, to learn from this information and automatically recommend the next configuration to examine with the aim of maximising the quality of the processing or analysis. Compared to existing interactive machine learning tools that require domain expertise for per-class or per-pixel annotations, we rely on users’ explicit assessment of output quality of the cell profiling task at hand. We validated our interactive approach against the standard human trial-and-error scheme to optimise an object segmentation task using the standard software CellProfiler. Our toolkit enabled rapid optimisation of an object segmentation pipeline, increasing the quality of object segmentation over a pipeline optimised through trial-and-error. Users also attested to the ease of use and reduced cognitive load enabled by our machine learning strategy over the standard approach. We envision that our interactive machine learning approach can enhance the quality and efficiency of pipeline optimisation to democratise image-based cell profiling.},
	language = {en},
	number = {9},
	urldate = {2022-05-17},
	journal = {PLOS ONE},
	author = {Laux, Lisa and Cutiongco, Marie F. A. and Gadegaard, Nikolaj and Jensen, Bjørn Sand},
	month = sep,
	year = {2020},
	note = {Publisher: Public Library of Science},
	keywords = {Computational pipelines, Focal adhesions, Graphics pipelines, Image processing, Imaging techniques, Machine learning, Machine learning algorithms, Optimization},
	pages = {e0237972},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/D8BLLLDY/Laux et al. - 2020 - Interactive machine learning for fast and robust c.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/C4BEHCLH/article.html:text/html},
}


@article{ljosa_introduction_2009,
	title = {Introduction to the {Quantitative} {Analysis} of {Two}-{Dimensional} {Fluorescence} {Microscopy} {Images} for {Cell}-{Based} {Screening}},
	volume = {5},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000603},
	doi = {10.1371/journal.pcbi.1000603},
	language = {en},
	number = {12},
	urldate = {2022-05-17},
	journal = {PLOS Computational Biology},
	author = {Ljosa, Vebjorn and Carpenter, Anne E.},
	month = dec,
	year = {2009},
	note = {Publisher: Public Library of Science},
	keywords = {Bright field microscopy, Computer imaging, Computer software, Fluorescence imaging, Image analysis, Imaging techniques, Open source software, Software tools},
	pages = {e1000603},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/S5PGJIZ9/Ljosa and Carpenter - 2009 - Introduction to the Quantitative Analysis of Two-D.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/DABIY6B9/article.html:text/html},
}

@article{battich_image-based_2013,
	title = {Image-based transcriptomics in thousands of single human cells at single-molecule resolution},
	volume = {10},
	copyright = {2013 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/nmeth.2657},
	doi = {10.1038/nmeth.2657},
	abstract = {An automated experimental and software pipeline for large-scale FISH enables spatial transcriptomics in thousands of single human cells at single-molecule resolution.},
	language = {en},
	number = {11},
	urldate = {2022-05-17},
	journal = {Nature Methods},
	author = {Battich, Nico and Stoeger, Thomas and Pelkmans, Lucas},
	month = nov,
	year = {2013},
	note = {Number: 11
Publisher: Nature Publishing Group},
	keywords = {Fluorescence in situ hybridization, Gene expression, High-throughput screening, Transcriptomics},
	pages = {1127--1133},
	file = {Snapshot:/Users/arthur/Zotero/storage/MWWSYUMV/nmeth.html:text/html},
}

@article{battich_control_2015,
	title = {Control of {Transcript} {Variability} in {Single} {Mammalian} {Cells}},
	volume = {163},
	issn = {0092-8674, 1097-4172},
	url = {https://www.cell.com/cell/abstract/S0092-8674(15)01498-1},
	doi = {10.1016/j.cell.2015.11.018},
	language = {English},
	number = {7},
	urldate = {2022-05-17},
	journal = {Cell},
	author = {Battich, Nico and Stoeger, Thomas and Pelkmans, Lucas},
	month = dec,
	year = {2015},
	pmid = {26687353},
	note = {Publisher: Elsevier},
	pages = {1596--1610},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/RF7ZFEJG/Battich et al. - 2015 - Control of Transcript Variability in Single Mammal.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/8SDAPT2S/S0092-8674(15)01498-1.html:text/html},
}

@article{CHOUAIB_2020,
	title = {A Dual Protein-mRNA Localization Screen Reveals Compartmentalized Translation and Widespread Co-translational RNA Targeting},
	journal = {Developmental Cell},
	volume = {54},
	number = {6},
	pages = {773-791.e5},
	year = {2020},
	issn = {1534-5807},
	doi = {https://doi.org/10.1016/j.devcel.2020.07.010},
	url = {https://www.sciencedirect.com/science/article/pii/S1534580720305840},
	author = {Racha Chouaib and Adham Safieddine and Xavier Pichon and Arthur Imbert and Oh Sung Kwon and Aubin Samacoits and Abdel-Meneem Traboulsi and Marie-Cécile Robert and Nikolay Tsanov and Emeline Coleno and Ina Poser and Christophe Zimmer and Anthony Hyman and Hervé {Le Hir} and Kazem Zibara and Marion Peter and Florian Mueller and Thomas Walter and Edouard Bertrand},
	keywords = {RNA localization, local translation, RNA transport, smFISH, translation factories, co-translational targeting, ASPM, Beta-catenin},
	abstract = {Summary
	Local translation allows spatial control of gene expression. Here, we performed a dual protein-mRNA localization screen, using smFISH on 523 human cell lines expressing GFP-tagged genes. 32 mRNAs displayed specific cytoplasmic localizations with local translation at unexpected locations, including cytoplasmic protrusions, cell edges, endosomes, Golgi, the nuclear envelope, and centrosomes, the latter being cell-cycle-dependent. Automated classification of mRNA localization patterns revealed a high degree of intercellular heterogeneity. Surprisingly, mRNA localization frequently required ongoing translation, indicating widespread co-translational RNA targeting. Interestingly, while P-body accumulation was frequent (15 mRNAs), four mRNAs accumulated in foci that were distinct structures. These foci lacked the mature protein, but nascent polypeptide imaging showed that they were specialized translation factories. For β-catenin, foci formation was regulated by Wnt, relied on APC-dependent polysome aggregation, and led to nascent protein degradation. Thus, translation factories uniquely regulate nascent protein metabolism and create a fine granular compartmentalization of translation.}
}

@article{safieddine_choreography_2021,
	title = {A choreography of centrosomal {mRNAs} reveals a conserved localization mechanism involving active polysome transport},
	volume = {12},
	copyright = {2021 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-21585-7},
	doi = {10.1038/s41467-021-21585-7},
	abstract = {Local translation allows for a spatial control of gene expression. Here, we use high-throughput smFISH to screen centrosomal protein-coding genes, and we describe 8 human mRNAs accumulating at centrosomes. These mRNAs localize at different stages during cell cycle with a remarkable choreography, indicating a finely regulated translational program at centrosomes. Interestingly, drug treatments and reporter analyses reveal a common translation-dependent localization mechanism requiring the nascent protein. Using ASPM and NUMA1 as models, single mRNA and polysome imaging reveals active movements of endogenous polysomes towards the centrosome at the onset of mitosis, when these mRNAs start localizing. ASPM polysomes associate with microtubules and localize by either motor-driven transport or microtubule pulling. Remarkably, the Drosophila orthologs of the human centrosomal mRNAs also localize to centrosomes and also require translation. These data identify a conserved family of centrosomal mRNAs that localize by active polysome transport mediated by nascent proteins.},
	language = {en},
	number = {1},
	urldate = {2022-06-28},
	journal = {Nature Communications},
	author = {Safieddine, Adham and Coleno, Emeline and Salloum, Soha and Imbert, Arthur and Traboulsi, Abdel-Meneem and Kwon, Oh Sung and Lionneton, Frederic and Georget, Virginie and Robert, Marie-Cécile and Gostan, Thierry and Lecellier, Charles-Henri and Chouaib, Racha and Pichon, Xavier and Le Hir, Hervé and Zibara, Kazem and Mueller, Florian and Walter, Thomas and Peter, Marion and Bertrand, Edouard},
	month = mar,
	year = {2021},
	keywords = {High-throughput screening, Molecular imaging, RNA metabolism},
	pages = {1352},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/L2W9WBYV/Safieddine et al. - 2021 - A choreography of centrosomal mRNAs reveals a cons.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/QDU24VXV/s41467-021-21585-7.html:text/html},
}

@article{pichon_kinesin_2021,
	title = {The kinesin {KIF1C} transports {APC}-dependent {mRNAs} to cell protrusions},
	volume = {27},
	issn = {1355-8382, 1469-9001},
	url = {http://rnajournal.cshlp.org/content/27/12/1528},
	doi = {10.1261/rna.078576.120},
	abstract = {RNA localization and local translation are important for numerous cellular functions. In mammals, a class of mRNAs localize to cytoplasmic protrusions in an APC-dependent manner, with roles during cell migration. Here, we investigated this localization mechanism. We found that the KIF1C motor interacts with APC-dependent mRNAs and is required for their localization. Live cell imaging revealed rapid, active transport of single mRNAs over long distances that requires both microtubules and KIF1C. Two-color imaging directly revealed single mRNAs transported by single KIF1C motors, with the 3′UTR being sufficient to trigger KIF1C-dependent RNA transport and localization. Moreover, KIF1C remained associated with peripheral, multimeric RNA clusters and was required for their formation. These results reveal a widespread RNA transport pathway in mammalian cells, in which the KIF1C motor has a dual role in transporting RNAs and clustering them within cytoplasmic protrusions. Interestingly, KIF1C also transports its own mRNA, suggesting a possible feedback loop acting at the level of mRNA transport.},
	language = {en},
	number = {12},
	urldate = {2022-06-28},
	journal = {RNA},
	author = {Pichon, Xavier and Moissoglu, Konstadinos and Coleno, Emeline and Wang, Tianhong and Imbert, Arthur and Robert, Marie-Cécile and Peter, Marion and Chouaib, Racha and Walter, Thomas and Mueller, Florian and Zibara, Kazem and Bertrand, Edouard and Mili, Stavroula},
	month = jan,
	year = {2021},
	pmid = {34493599},
	keywords = {cytoplasmic protrusions, local translation, RNA localization, RNA transport},
	pages = {1528--1544},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/BKYDP248/Pichon et al. - 2021 - The kinesin KIF1C transports APC-dependent mRNAs t.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/3T2XJ7P9/1528.html:text/html},
}

@inproceedings{dubois_deep_2019,
	title = {A {Deep} {Learning} {Approach} {To} {Identify} {mRNA} {Localization} {Patterns}},
	doi = {10.1109/ISBI.2019.8759235},
	abstract = {The localization of messenger RNA (mRNA) molecules inside cells play an important role for the local control of gene expression. However, the localization patterns of many mRNAs remain unknown and poorly understood. Single Molecule Fluorescence in Situ Hybridization (smFISH) allows for the visualization of individual mRNA molecules in cells. This method is now scalable and can be applied in High Content Screening (HCS) mode. Here, we propose a computational workflow based on deep convolutional neural networks trained on simulated data to identify different localization patterns from large-scale smFISH data.},
	booktitle = {2019 {IEEE} 16th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI} 2019)},
	author = {Dubois, Rémy and Imbert, Arthur and Samacoïts, Aubin and Peter, Marion and Bertrand, Edouard and Müller, Florian and Walter, Thomas},
	month = apr,
	year = {2019},
	note = {ISSN: 1945-8452},
	keywords = {Data visualization, Deep learning, Deep Learning, Feature extraction, Gene expression, High Content Screening, image simulation, Proteins, RNA, RNA localization, Spatial Transcriptomics, Three-dimensional displays},
	pages = {1386--1390},
	file = {IEEE Xplore Abstract Record:/Users/arthur/Zotero/storage/HD8ISRQA/8759235.html:text/html},
}

@article{stueland_rdi_2019,
	title = {{RDI} {Calculator}: {An} {Analysis} {Tool} to {Assess} {RNA} {Distributions} in {Cells}},
	volume = {9},
	copyright = {2019 The Author(s)},
	issn = {2045-2322},
	shorttitle = {{RDI} {Calculator}},
	url = {https://www.nature.com/articles/s41598-019-44783-2},
	doi = {10.1038/s41598-019-44783-2},
	abstract = {Localization of RNAs to various subcellular destinations has emerged as a widely used mechanism that regulates a large proportion of transcripts in polarized cells. A number of methodologies have been developed that allow detection and imaging of RNAs at single-molecule resolution. However, methodologies to quantitatively describe RNA distributions are limited. Such approaches usually rely on the identification of cytoplasmic and nuclear boundaries which are used as reference points. Here, we describe an automated, interactive image analysis program that facilitates the accurate generation of cellular outlines from single cells and the subsequent calculation of metrics that quantify how a population of RNA molecules is distributed in the cell cytoplasm. We apply this analysis to mRNAs in mouse and human cells to demonstrate how these metrics can highlight differences in the distribution patterns of distinct RNA species. We further discuss considerations for the practical use of this tool. This program provides a way to facilitate and expedite the analysis of subcellular RNA localization for mechanistic and functional studies.},
	language = {en},
	number = {1},
	urldate = {2022-06-28},
	journal = {Scientific Reports},
	author = {Stueland, Michael and Wang, Tianhong and Park, Hye Yoon and Mili, Stavroula},
	month = jun,
	year = {2019},
	keywords = {Fluorescence in situ hybridization, Molecular imaging, RNA transport, Software},
	pages = {8267},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/MMPK4UPG/Stueland et al. - 2019 - RDI Calculator An Analysis Tool to Assess RNA Dis.pdf:application/pdf},
}

@article{Iandola_2016,
	author    = {Forrest N. Iandola and
			   Matthew W. Moskewicz and
			   Khalid Ashraf and
			   Song Han and
			   William J. Dally and
			   Kurt Keutzer},
	title     = {SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and {\textless}1MB model size},
	journal   = {CoRR},
	volume    = {abs/1602.07360},
	year      = {2016},
	url       = {http://arxiv.org/abs/1602.07360},
	eprinttype = {arXiv},
	eprint    = {1602.07360},
	timestamp = {Fri, 20 Nov 2020 16:16:06 +0100},
	biburl    = {https://dblp.org/rec/journals/corr/IandolaMAHDK16.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{vandermaaten_2008,
	author  = {Laurens van der Maaten and Geoffrey Hinton},
	title   = {Visualizing Data using t-SNE},
	journal = {Journal of Machine Learning Research},
	year    = {2008},
	volume  = {9},
	number  = {86},
	pages   = {2579--2605},
	url     = {http://jmlr.org/papers/v9/vandermaaten08a.html}
}

@article{wattenberg2016,
	author = {Wattenberg, Martin and Viégas, Fernanda and Johnson, Ian},
	title = {How to Use t-SNE Effectively},
	journal = {Distill},
	year = {2016},
	url = {http://distill.pub/2016/misread-tsne},
	doi = {10.23915/distill.00002}
}

@article{olah2017feature,
	author = {Olah, Chris and Mordvintsev, Alexander and Schubert, Ludwig},
	title = {Feature Visualization},
	journal = {Distill},
	year = {2017},
	note = {https://distill.pub/2017/feature-visualization},
	doi = {10.23915/distill.00007}
}

@article{olah2018the,
	author = {Olah, Chris and Satyanarayan, Arvind and Johnson, Ian and Carter, Shan and Schubert, Ludwig and Ye, Katherine and Mordvintsev, Alexander},
	title = {The Building Blocks of Interpretability},
	journal = {Distill},
	year = {2018},
	note = {https://distill.pub/2018/building-blocks},
	doi = {10.23915/distill.00010}
}

@inproceedings{Yarin_2016,
	author = {Gal, Yarin and Ghahramani, Zoubin},
	title = {Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning},
	year = {2016},
	publisher = {JMLR.org},
	abstract = {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs - extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and nonlinearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.},
	booktitle = {Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48},
	pages = {1050–1059},
	numpages = {10},
	location = {New York, NY, USA},
	series = {ICML'16}
}

@inproceedings{Rosanne_2018,
	author = {Liu, Rosanne and Lehman, Joel and Molino, Piero and Petroski Such, Felipe and Frank, Eric and Sergeev, Alex and Yosinski, Jason},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {An intriguing failing of convolutional neural networks and the CoordConv solution},
	url = {https://proceedings.neurips.cc/paper/2018/file/60106888f8977b71e1f15db7bc9a88d1-Paper.pdf},
	volume = {31},
	year = {2018}
}

@InProceedings{Qi_2017_CVPR,
	author = {Qi, Charles R. and Su, Hao and Mo, Kaichun and Guibas, Leonidas J.},
	title = {PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {July},
	year = {2017}
}

@article{Wang_2019,
	author = {Wang, Yue and Sun, Yongbin and Liu, Ziwei and Sarma, Sanjay E. and Bronstein, Michael M. and Solomon, Justin M.},
	title = {Dynamic Graph CNN for Learning on Point Clouds},
	year = {2019},
	issue_date = {October 2019},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {38},
	number = {5},
	issn = {0730-0301},
	url = {https://doi.org/10.1145/3326362},
	doi = {10.1145/3326362},
	abstract = {Point clouds provide a flexible geometric representation suitable for countless applications in computer graphics; they also comprise the raw output of most 3D data acquisition devices. While hand-designed features on point clouds have long been proposed in graphics and vision, however, the recent overwhelming success of convolutional neural networks (CNNs) for image analysis suggests the value of adapting insight from CNN to the point cloud world. Point clouds inherently lack topological information, so designing a model to recover topology can enrich the representation power of point clouds. To this end, we propose a new neural network module dubbed EdgeConv suitable for CNN-based high-level tasks on point clouds, including classification and segmentation. EdgeConv acts on graphs dynamically computed in each layer of the network. It is differentiable and can be plugged into existing architectures. Compared to existing modules operating in extrinsic space or treating each point independently, EdgeConv has several appealing properties: It incorporates local neighborhood information; it can be stacked applied to learn global shape properties; and in multi-layer systems affinity in feature space captures semantic characteristics over potentially long distances in the original embedding. We show the performance of our model on standard benchmarks, including ModelNet40, ShapeNetPart, and S3DIS.},
	journal = {ACM Trans. Graph.},
	month = {oct},
	articleno = {146},
	numpages = {12},
	keywords = {classification, Point cloud, segmentation}
}

@InProceedings{Zhao_2021_ICCV,
    author    = {Zhao, Hengshuang and Jiang, Li and Jia, Jiaya and Torr, Philip H.S. and Koltun, Vladlen},
    title     = {Point Transformer},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {16259-16268}
}

@inproceedings{ma2022rethinking,
	title={Rethinking Network Design and Local Geometry in Point Cloud: A Simple Residual {MLP} Framework},
	author={Xu Ma and Can Qin and Haoxuan You and Haoxi Ran and Yun Fu},
	booktitle={International Conference on Learning Representations},
	year={2022},
	url={https://openreview.net/forum?id=3Pbra-_u76D}
}

@inproceedings{Hamilton_2017,
	author = {Hamilton, Will and Ying, Zhitao and Leskovec, Jure},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Inductive Representation Learning on Large Graphs},
	url = {https://proceedings.neurips.cc/paper/2017/file/5dd9db5e033da9c6fb5ba83c7a7ebea9-Paper.pdf},
	volume = {30},
	year = {2017}
}

@article{Partel_2021,
	author = {Partel, Gabriele and Wählby, Carolina},
	title = {Spage2vec: Unsupervised representation of localized spatial gene expression signatures},
	journal = {The FEBS Journal},
	volume = {288},
	number = {6},
	pages = {1859-1870},
	keywords = {gene expression, graph representation learning, RNA profiling, spatial transcriptomics, tissue analysis},
	doi = {https://doi.org/10.1111/febs.15572},
	url = {https://febs.onlinelibrary.wiley.com/doi/abs/10.1111/febs.15572},
	eprint = {https://febs.onlinelibrary.wiley.com/doi/pdf/10.1111/febs.15572},
	abstract = {Spatial investigation of cellular heterogeneity is essential to understand tissue organization and function. We present spage2vec, an unsupervised segmentation-free approach for analyzing the spatial transcriptomic landscape at subcellular resolution. Spage2vec models the spatial gene expression as a graph and extracts localized gene expression signatures involved in cellular and subcellular biological processes.},
	year = {2021}
}

@InProceedings{Xiang_2021_ICCV,
    author    = {Xiang, Tiange and Zhang, Chaoyi and Song, Yang and Yu, Jianhui and Cai, Weidong},
    title     = {Walk in the Cloud: Learning Curves for Point Clouds Shape Analysis},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {915-924}
}

@inproceedings{Qi_2017,
	author = {Qi, Charles Ruizhongtai and Yi, Li and Su, Hao and Guibas, Leonidas J},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space},
	url = {https://proceedings.neurips.cc/paper/2017/file/d8bf84be3800d12f74d8b05e9b89836f-Paper.pdf},
	volume = {30},
	year = {2017}
}

@inproceedings{Li_2018,
	author = {Li, Yangyan and Bu, Rui and Sun, Mingchao and Wu, Wei and Di, Xinhan and Chen, Baoquan},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {PointCNN: Convolution On X-Transformed Points},
	url = {https://proceedings.neurips.cc/paper/2018/file/f5f8590cd58a54e94377e6ae2eded4d9-Paper.pdf},
	volume = {31},
	year = {2018}
}

@INPROCEEDINGS{Maturana_2015,
	author={Maturana, Daniel and Scherer, Sebastian},
	booktitle={2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
	title={VoxNet: A 3D Convolutional Neural Network for real-time object recognition},
	year={2015},
	pages={922-928},
	doi={10.1109/IROS.2015.7353481}
}

@InProceedings{Thomas_2019_ICCV,
	author = {Thomas, Hugues and Qi, Charles R. and Deschaud, Jean-Emmanuel and Marcotegui, Beatriz and Goulette, Francois and Guibas, Leonidas J.},
	title = {KPConv: Flexible and Deformable Convolution for Point Clouds},
	booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
	month = {October},
	year = {2019}
}

@InProceedings{Wu_2019_CVPR,
	author = {Wu, Wenxuan and Qi, Zhongang and Fuxin, Li},
	title = {PointConv: Deep Convolutional Networks on 3D Point Clouds},
	booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2019}
}

@inproceedings{Zaheer_2017,
	author = {Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Russ R and Smola, Alexander J},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Deep Sets},
	url = {https://proceedings.neurips.cc/paper/2017/file/f22e4747da1aa27e363d86d40ff442fe-Paper.pdf},
	volume = {30},
	year = {2017}
}

@article{Savulescu_2021,
	title = {Prediction of RNA subcellular localization: Learning from heterogeneous data sources},
	journal = {iScience},
	volume = {24},
	number = {11},
	pages = {103298},
	year = {2021},
	issn = {2589-0042},
	doi = {https://doi.org/10.1016/j.isci.2021.103298},
	url = {https://www.sciencedirect.com/science/article/pii/S2589004221012670},
	author = {Anca Flavia Savulescu and Emmanuel Bouilhol and Nicolas Beaume and Macha Nikolski},
	keywords = {Cell biology, Transcriptomics, Machine learning},
	abstract = {Summary RNA subcellular localization has recently emerged as a widespread phenomenon, which may apply to the majority of RNAs. The two main sources of data for characterization of RNA localization are sequence features and microscopy images, such as obtained from single-molecule fluorescent in situ hybridization-based techniques. Although such imaging data are ideal for characterization of RNA distribution, these techniques remain costly, time-consuming, and technically challenging. Given these limitations, imaging data exist only for a limited number of RNAs. We argue that the field of RNA localization would greatly benefit from complementary techniques able to characterize location of RNA. Here we discuss the importance of RNA localization and the current methodology in the field, followed by an introduction on prediction of location of molecules. We then suggest a machine learning approach based on the integration between imaging localization data and sequence-based data to assist in characterization of RNA localization on a transcriptome level.}
}

@INPROCEEDINGS{Lowe_1999,
	author={Lowe, D.G.},
	booktitle={Proceedings of the Seventh IEEE International Conference on Computer Vision},
	title={Object recognition from local scale-invariant features},
	year={1999},
	volume={2},
	pages={1150-1157 vol.2},
	doi={10.1109/ICCV.1999.790410}
}

@InProceedings{Bay_2006,
	author="Bay, Herbert
	and Tuytelaars, Tinne
	and Van Gool, Luc",
	editor="Leonardis, Ale{\v{s}}
	and Bischof, Horst
	and Pinz, Axel",
	title="SURF: Speeded Up Robust Features",
	booktitle="Computer Vision -- ECCV 2006",
	year="2006",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="404--417",
	abstract="In this paper, we present a novel scale- and rotation-invariant interest point detector and descriptor, coined SURF (Speeded Up Robust Features). It approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster.",
	isbn="978-3-540-33833-8"
}

@InProceedings{Huang_2017_CVPR,
	author = {Huang, Gao and Liu, Zhuang and van der Maaten, Laurens and Weinberger, Kilian Q.},
	title = {Densely Connected Convolutional Networks},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {July},
	year = {2017}
}

@InProceedings{Tan_2019,
  title = 	 {{E}fficient{N}et: Rethinking Model Scaling for Convolutional Neural Networks},
  author =       {Tan, Mingxing and Le, Quoc},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {6105--6114},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/tan19a/tan19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/tan19a.html},
  abstract = 	 {Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are given. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on MobileNets and ResNet. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves stateof-the-art 84.4% top-1 / 97.1% top-5 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet (Huang et al., 2018). Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flower (98.8%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters.}
}

@InProceedings{Szegedy_2016_CVPR,
	author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
	title = {Rethinking the Inception Architecture for Computer Vision},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2016}
}

@InProceedings{He_2016_CVPR,
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	title = {Deep Residual Learning for Image Recognition},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2016}
}

@misc{Mikolov_2013,
  doi = {10.48550/ARXIV.1301.3781},
  url = {https://arxiv.org/abs/1301.3781},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Efficient Estimation of Word Representations in Vector Space},
  publisher = {arXiv},
  year = {2013},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{Joulin_2016,
  doi = {10.48550/ARXIV.1607.01759},
  url = {https://arxiv.org/abs/1607.01759},
  author = {Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Mikolov, Tomas},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Bag of Tricks for Efficient Text Classification},
  publisher = {arXiv},
  year = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{Pennington_2014,
    title = "{G}lo{V}e: Global Vectors for Word Representation",
    author = "Pennington, Jeffrey  and
      Socher, Richard  and
      Manning, Christopher",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D14-1162",
    doi = "10.3115/v1/D14-1162",
    pages = "1532--1543",
}

@article{boland_automated_1998,
	title = {Automated recognition of patterns characteristic of subcellular structures in fluorescence microscopy images},
	volume = {33},
	issn = {0196-4763},
	abstract = {Methods for numerical description and subsequent classification of cellular protein localization patterns are described. Images representing the localization patterns of 4 proteins and DNA were obtained using fluorescence microscopy and divided into distinct training and test sets. The images were processed to remove out-of-focus and background fluorescence and 2 sets of numeric features were generated: Zernike moments and Haralick texture features. These feature sets were used as inputs to either a classification tree or a neural network. Classifier performance (the average percent of each type of image correctly classified) on previously unseen images ranged from 63\% for a classification tree using Zernike moments to 88\% for a backpropagation neural network using a combination of features from the 2 feature sets. These results demonstrate the feasibility of applying pattern recognition methods to subcellular localization patterns, enabling sets of previously unseen images from a single class to be classified with an expected accuracy greater than 99\%. This will provide not only a new automated way to describe proteins, based on localization rather than sequence, but also has potential application in the automation of microscope functions and in the field of gene discovery.},
	language = {eng},
	number = {3},
	journal = {Cytometry},
	author = {Boland, M. V. and Markey, M. K. and Murphy, R. F.},
	month = nov,
	year = {1998},
	pmid = {9822349},
	keywords = {Image Enhancement, Image Processing, Computer-Assisted, Microscopy, Fluorescence, Pattern Recognition, Automated, Proteins},
	pages = {366--375},
}

@article{ouyang_analysis_2019,
	title = {Analysis of the {Human} {Protein} {Atlas} {Image} {Classification} competition},
	volume = {16},
	copyright = {2019 The Author(s)},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/s41592-019-0658-6},
	doi = {10.1038/s41592-019-0658-6},
	abstract = {Pinpointing subcellular protein localizations from microscopy images is easy to the trained eye, but challenging to automate. Based on the Human Protein Atlas image collection, we held a competition to identify deep learning solutions to solve this task. Challenges included training on highly imbalanced classes and predicting multiple labels per image. Over 3 months, 2,172 teams participated. Despite convergence on popular networks and training techniques, there was considerable variety among the solutions. Participants applied strategies for modifying neural networks and loss functions, augmenting data and using pretrained networks. The winning models far outperformed our previous effort at multi-label classification of protein localization patterns by {\textasciitilde}20\%. These models can be used as classifiers to annotate new images, feature extractors to measure pattern similarity or pretrained networks for a wide range of biological applications.},
	language = {en},
	number = {12},
	urldate = {2022-07-02},
	journal = {Nature Methods},
	author = {Ouyang, Wei and Winsnes, Casper F. and Hjelmare, Martin and Cesnik, Anthony J. and Åkesson, Lovisa and Xu, Hao and Sullivan, Devin P. and Dai, Shubin and Lan, Jun and Jinmo, Park and Galib, Shaikat M. and Henkel, Christof and Hwang, Kevin and Poplavskiy, Dmytro and Tunguz, Bojan and Wolfinger, Russel D. and Gu, Yinzheng and Li, Chuanpeng and Xie, Jinbin and Buslov, Dmitry and Fironov, Sergei and Kiselev, Alexander and Panchenko, Dmytro and Cao, Xuan and Wei, Runmin and Wu, Yuanhao and Zhu, Xun and Tseng, Kuan-Lun and Gao, Zhifeng and Ju, Cheng and Yi, Xiaohan and Zheng, Hongdong and Kappel, Constantin and Lundberg, Emma},
	month = dec,
	year = {2019},
	keywords = {Image processing, Machine learning, Organelles},
	pages = {1254--1261},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/TJ2RGH3D/Ouyang et al. - 2019 - Analysis of the Human Protein Atlas Image Classifi.pdf:application/pdf},
}

@article{sullivan_deep_2018,
	title = {Deep learning is combined with massive-scale citizen science to improve large-scale image classification},
	volume = {36},
	copyright = {2018 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1546-1696},
	url = {https://www.nature.com/articles/nbt.4225},
	doi = {10.1038/nbt.4225},
	abstract = {Pattern recognition in imaging data by {\textgreater}300,000 players of a global, online, commercial computer game is combined with deep learning to improve the accuracy of annotation of subcellular protein localization.},
	language = {en},
	number = {9},
	urldate = {2022-07-02},
	journal = {Nature Biotechnology},
	author = {Sullivan, Devin P. and Winsnes, Casper F. and Åkesson, Lovisa and Hjelmare, Martin and Wiking, Mikaela and Schutten, Rutger and Campbell, Linzi and Leifsson, Hjalti and Rhodes, Scott and Nordgren, Andie and Smith, Kevin and Revaz, Bernard and Finnbogason, Bergur and Szantner, Attila and Lundberg, Emma},
	month = oct,
	year = {2018},
	keywords = {Biotechnology, Cell biology, Computational biology and bioinformatics, Scientific community},
	pages = {820--828},
	file = {Full Text:/Users/arthur/Zotero/storage/I4WI2AMA/Sullivan et al. - 2018 - Deep learning is combined with massive-scale citiz.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/HMCCAPLV/nbt.html:text/html},
}

@inproceedings{Grover_2016,
	author = {Grover, Aditya and Leskovec, Jure},
	title = {Node2vec: Scalable Feature Learning for Networks},
	year = {2016},
	isbn = {9781450342322},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/2939672.2939754},
	doi = {10.1145/2939672.2939754},
	abstract = {Prediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node's network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations.We demonstrate the efficacy of node2vec over existing state-of-the-art techniques on multi-label classification and link prediction in several real-world networks from diverse domains. Taken together, our work represents a new way for efficiently learning state-of-the-art task-independent representations in complex networks.},
	booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {855–864},
	numpages = {10},
	keywords = {graph representations, feature learning, node embeddings, information networks},
	location = {San Francisco, California, USA},
	series = {KDD '16}
}

@article{Uhlen_2015,
	author = {Mathias Uhlén  and Linn Fagerberg  and Björn M. Hallström  and Cecilia Lindskog  and Per Oksvold  and Adil Mardinoglu  and Åsa Sivertsson  and Caroline Kampf  and Evelina Sjöstedt  and Anna Asplund  and IngMarie Olsson  and Karolina Edlund  and Emma Lundberg  and Sanjay Navani  and Cristina Al-Khalili Szigyarto  and Jacob Odeberg  and Dijana Djureinovic  and Jenny Ottosson Takanen  and Sophia Hober  and Tove Alm  and Per-Henrik Edqvist  and Holger Berling  and Hanna Tegel  and Jan Mulder  and Johan Rockberg  and Peter Nilsson  and Jochen M. Schwenk  and Marica Hamsten  and Kalle von Feilitzen  and Mattias Forsberg  and Lukas Persson  and Fredric Johansson  and Martin Zwahlen  and Gunnar von Heijne  and Jens Nielsen  and Fredrik Pontén },
	title = {Tissue-based map of the human proteome},
	journal = {Science},
	volume = {347},
	number = {6220},
	pages = {1260419},
	year = {2015},
	doi = {10.1126/science.1260419},
	URL = {https://www.science.org/doi/abs/10.1126/science.1260419},
	eprint = {https://www.science.org/doi/pdf/10.1126/science.1260419},
	abstract = {Sequencing the human genome gave new insights into human biology and disease. However, the ultimate goal is to understand the dynamic expression of each of the approximately 20,000 protein-coding genes and the function of each protein. Uhlén et al. now present a map of protein expression across 32 human tissues. They not only measured expression at an RNA level, but also used antibody profiling to precisely localize the corresponding proteins. An interactive website allows exploration of expression patterns across the human body. Science, this issue 10.1126/science.1260419 Transcriptomics and immunohistochemistry map protein expression across 32 human tissues. Resolving the molecular details of proteome variation in the different tissues and organs of the human body will greatly increase our knowledge of human biology and disease. Here, we present a map of the human tissue proteome based on an integrated omics approach that involves quantitative transcriptomics at the tissue and organ level, combined with tissue microarray–based immunohistochemistry, to achieve spatial localization of proteins down to the single-cell level. Our tissue-based analysis detected more than 90\% of the putative protein-coding genes. We used this approach to explore the human secretome, the membrane proteome, the druggable proteome, the cancer proteome, and the metabolic functions in 32 different tissues and organs. All the data are integrated in an interactive Web-based database that allows exploration of individual proteins, as well as navigation of global expression patterns, in all major tissues and organs in the human body.}
}

@misc{tensorflow_2015,
	title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
	url={https://www.tensorflow.org/},
	note={Software available from tensorflow.org},
	author={
		Mart\'{i}n~Abadi and
		Ashish~Agarwal and
		Paul~Barham and
		Eugene~Brevdo and
		Zhifeng~Chen and
		Craig~Citro and
		Greg~S.~Corrado and
		Andy~Davis and
		Jeffrey~Dean and
		Matthieu~Devin and
		Sanjay~Ghemawat and
		Ian~Goodfellow and
		Andrew~Harp and
		Geoffrey~Irving and
		Michael~Isard and
		Yangqing Jia and
		Rafal~Jozefowicz and
		Lukasz~Kaiser and
		Manjunath~Kudlur and
		Josh~Levenberg and
		Dandelion~Man\'{e} and
		Rajat~Monga and
		Sherry~Moore and
		Derek~Murray and
		Chris~Olah and
		Mike~Schuster and
		Jonathon~Shlens and
		Benoit~Steiner and
		Ilya~Sutskever and
		Kunal~Talwar and
		Paul~Tucker and
		Vincent~Vanhoucke and
		Vijay~Vasudevan and
		Fernanda~Vi\'{e}gas and
		Oriol~Vinyals and
		Pete~Warden and
		Martin~Wattenberg and
		Martin~Wicke and
		Yuan~Yu and
		Xiaoqiang~Zheng},
	  year={2015},
}

@article{Diederik_2015,
	title={Adam: A Method for Stochastic Optimization},
	author={Diederik P. Kingma and Jimmy Ba},
	journal={CoRR},
	year={2015},
	volume={abs/1412.6980}
}

@article{McInnes2018,
	doi = {10.21105/joss.00861},
	url = {https://doi.org/10.21105/joss.00861},
	year = {2018},
	publisher = {The Open Journal},
	volume = {3},
	number = {29},
	pages = {861},
	author = {Leland McInnes and John Healy and Nathaniel Saul and Lukas Großberger},
	title = {UMAP: Uniform Manifold Approximation and Projection},
	journal = {Journal of Open Source Software}
}

@article{chang2011libsvm,
	title={LIBSVM: A library for support vector machines},
	author={Chang, Chih-Chung and Lin, Chih-Jen},
	journal={ACM transactions on intelligent systems and technology (TIST)},
	volume={2},
	number={3},
	pages={1--27},
	year={2011},
	publisher={Acm New York, NY, USA}
}

@INPROCEEDINGS{Platt99probabilisticoutputs,
	author = {John C. Platt},
	title = {Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods},
	booktitle = {ADVANCES IN LARGE MARGIN CLASSIFIERS},
	year = {1999},
	pages = {61--74},
	publisher = {MIT Press}
}

@book{ripley2005spatial,
	title={Spatial Statistics},
	author={Ripley, B.D.},
	isbn={9780471725206},
	lccn={80026104},
	series={Wiley Series in Probability and Statistics},
	url={https://books.google.fr/books?id=BDDPTdohXeYC},
	year={2005},
	publisher={Wiley}
}

@misc{savulescu_dypfish_2019,
	title = {{DypFISH}: {Dynamic} {Patterned} {FISH} to {Interrogate} {RNA} and {Protein} {Spatial} and {Temporal} {Subcellular} {Distribution}},
	copyright = {© 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
	shorttitle = {{DypFISH}},
	url = {https://www.biorxiv.org/content/10.1101/536383v1},
	doi = {10.1101/536383},
	abstract = {Advances in single cell RNA sequencing have allowed for the identification and characterization of cellular subtypes based on quantification of the number of transcripts in each cell. However, cells may differ not only in the number of mRNA transcripts that they exhibit, but also in their spatial and temporal distribution, intrinsic to the definition of their cellular state. Here we describe DypFISH, an approach to quantitatively investigate the spatial and temporal subcellular localization of RNA and protein, by combining micropatterning of cells with fluorescence microscopy at high resolution. We introduce a range of analytical techniques for quantitatively interrogating single molecule RNA FISH data in combination with protein immunolabeling over time. Strikingly, our results show that constraining cellular architecture reduces variation in subcellular mRNA and protein distributions, allowing the characterization of their localization and dynamics with high reproducibility. Many tissues contain cells that exist in similar constrained architectures. Thus DypFISH reveals reproducible patterns of clustering, strong correlative influences of mRNA-protein localization on MTOC orientation when they are present and interdependent dynamics globally and at specific subcellular locations which can be extended to physiological systems.},
	language = {en},
	urldate = {2022-07-07},
	publisher = {bioRxiv},
	author = {Savulescu, Anca F. and Brackin, Robyn and Bouilhol, Emmanuel and Dartigues, Benjamin and Warrell, Jonathan H. and Pimentel, Mafalda R. and Dallongeville, Stephane and Schmoranzer, Jan and Olivo-Marin, Jean-Christophe and Gomes, Edgar R. and Nikolski, Macha and Mhlanga, Musa M.},
	month = jan,
	year = {2019},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/Y84Z7MSY/Savulescu et al. - 2019 - DypFISH Dynamic Patterned FISH to Interrogate RNA.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/UPPC4S86/536383v1.html:text/html},
}

@article{lecuyer_global_2007,
	title = {Global analysis of {mRNA} localization reveals a prominent role in organizing cellular architecture and function},
	volume = {131},
	issn = {0092-8674},
	doi = {10.1016/j.cell.2007.08.003},
	abstract = {Although subcellular mRNA trafficking has been demonstrated as a mechanism to control protein distribution, it is generally believed that most protein localization occurs subsequent to translation. To address this point, we developed and employed a high-resolution fluorescent in situ hybridization procedure to comprehensively evaluate mRNA localization dynamics during early Drosophila embryogenesis. Surprisingly, of the 3370 genes analyzed, 71\% of those expressed encode subcellularly localized mRNAs. Dozens of new and striking localization patterns were observed, implying an equivalent variety of localization mechanisms. Tight correlations between mRNA distribution and subsequent protein localization and function, indicate major roles for mRNA localization in nucleating localized cellular machineries. A searchable web resource documenting mRNA expression and localization dynamics has been established and will serve as an invaluable tool for dissecting localization mechanisms and for predicting gene functions and interactions.},
	language = {eng},
	number = {1},
	journal = {Cell},
	author = {Lécuyer, Eric and Yoshida, Hideki and Parthasarathy, Neela and Alm, Christina and Babak, Tomas and Cerovina, Tanja and Hughes, Timothy R. and Tomancak, Pavel and Krause, Henry M.},
	month = oct,
	year = {2007},
	pmid = {17923096},
	keywords = {Animals, Cell Division, Cell Nucleus, Databases, Nucleic Acid, Drosophila melanogaster, Drosophila Proteins, Embryo, Nonmammalian, Gene Expression Profiling, Gene Expression Regulation, Developmental, In Situ Hybridization, Fluorescence, RNA, Messenger},
	pages = {174--187},
	file = {Full Text:/Users/arthur/Zotero/storage/LYITXPFN/Lécuyer et al. - 2007 - Global analysis of mRNA localization reveals a pro.pdf:application/pdf},
}

@misc{ba2016layer,
	author = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.},
	biburl = {https://www.bibsonomy.org/bibtex/2f6a77ee956c14b0ea1e902198b55f400/adulny},
	description = {[1607.06450] Layer Normalization},
	interhash = {e05449c2b435c503ef4c447a7c87dc78},
	intrahash = {f6a77ee956c14b0ea1e902198b55f400},
	keywords = {deep-learning layer-norm training training-efficiency},
	note = {cite arxiv:1607.06450},
	timestamp = {2021-04-20T12:31:53.000+0200},
	title = {Layer Normalization},
	url = {http://arxiv.org/abs/1607.06450},
	year = 2016
}

@inproceedings{NIPS2017_3f5ee243,
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Attention is All you Need},
	url = {https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
	volume = {30},
	year = {2017}
}

@misc{mah_bento_2022,
	title = {Bento: {A} toolkit for subcellular analysis of spatial transcriptomics data},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	shorttitle = {Bento},
	url = {https://www.biorxiv.org/content/10.1101/2022.06.10.495510v1},
	note = {https://www.biorxiv.org/content/10.1101/2022.06.10.495510v1},
	doi = {10.1101/2022.06.10.495510},
	language = {en},
	urldate = {2022-07-07},
	publisher = {bioRxiv},
	author = {Mah, Clarence K. and Ahmed, Noorsher and Lam, Dylan and Monell, Alexander and Kern, Colin and Han, Yuanyuan and Cesnik, Anthony J. and Lundberg, Emma and Zhu, Quan and Carter, Hannah and Yeo, Gene W.},
	year = {2022},
}

@article{mueller_fish-quant_2013,
	title = {{FISH}-quant: automatic counting of transcripts in {3D} {FISH} images},
	volume = {10},
	copyright = {2013 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1548-7105},
	shorttitle = {{FISH}-quant},
	url = {https://www.nature.com/articles/nmeth.2406},
	doi = {10.1038/nmeth.2406},
	language = {en},
	number = {4},
	urldate = {2022-05-17},
	journal = {Nature Methods},
	author = {Mueller, Florian and Senecal, Adrien and Tantale, Katjana and Marie-Nelly, Hervé and Ly, Nathalie and Collin, Olivier and Basyuk, Eugenia and Bertrand, Edouard and Darzacq, Xavier and Zimmer, Christophe},
	month = apr,
	year = {2013},
	note = {Number: 4
Publisher: Nature Publishing Group},
	keywords = {Computational biology and bioinformatics, Fluorescence in situ hybridization, RNA},
	pages = {277--278},
	file = {Snapshot:/Users/arthur/Zotero/storage/6Q3VB9HJ/nmeth.html:text/html;Submitted Version:/Users/arthur/Zotero/storage/J33ZFXMT/Mueller et al. - 2013 - FISH-quant automatic counting of transcripts in 3.pdf:application/pdf},
}

@inproceedings{pointfish_2022,
	title = {PointFISH: learning point cloud representations for RNA localization patterns},
	booktitle={2022 European Conference on Computer Vision (ECCV 2022) Workshop on BioImage Computing},
	author = {Imbert, Arthur and Mueller, Florian and Walter, Thomas},
	year = {2022}
}