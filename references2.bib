@article{schindelin_fiji_2012,
	title = {Fiji: an open-source platform for biological-image analysis},
	volume = {9},
	copyright = {2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1548-7105},
	shorttitle = {Fiji},
	url = {https://www.nature.com/articles/nmeth.2019},
	doi = {10.1038/nmeth.2019},
	abstract = {Presented is an overview of the image-analysis software platform Fiji, a distribution of ImageJ that updates the underlying ImageJ architecture and adds modern software design elements to expand the capabilities of the platform and facilitate collaboration between biologists and computer scientists.},
	language = {en},
	number = {7},
	urldate = {2022-06-21},
	journal = {Nature Methods},
	author = {Schindelin, Johannes and Arganda-Carreras, Ignacio and Frise, Erwin and Kaynig, Verena and Longair, Mark and Pietzsch, Tobias and Preibisch, Stephan and Rueden, Curtis and Saalfeld, Stephan and Schmid, Benjamin and Tinevez, Jean-Yves and White, Daniel James and Hartenstein, Volker and Eliceiri, Kevin and Tomancak, Pavel and Cardona, Albert},
	month = jul,
	year = {2012},
	keywords = {Imaging, Software},
	pages = {676--682},
	file = {Snapshot:/Users/arthur/Zotero/storage/PGSNPJXC/nmeth.html:text/html},
}

@article{mueller_fish-quant_2013,
	title = {{FISH}-quant: automatic counting of transcripts in {3D} {FISH} images},
	volume = {10},
	copyright = {2013 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1548-7105},
	shorttitle = {{FISH}-quant},
	url = {https://www.nature.com/articles/nmeth.2406},
	doi = {10.1038/nmeth.2406},
	language = {en},
	number = {4},
	urldate = {2022-05-17},
	journal = {Nature Methods},
	author = {Mueller, Florian and Senecal, Adrien and Tantale, Katjana and Marie-Nelly, Hervé and Ly, Nathalie and Collin, Olivier and Basyuk, Eugenia and Bertrand, Edouard and Darzacq, Xavier and Zimmer, Christophe},
	month = apr,
	year = {2013},
	keywords = {Computational biology and bioinformatics, Fluorescence in situ hybridization, RNA},
	pages = {277--278},
	file = {Snapshot:/Users/arthur/Zotero/storage/6Q3VB9HJ/nmeth.html:text/html;Submitted Version:/Users/arthur/Zotero/storage/J33ZFXMT/Mueller et al. - 2013 - FISH-quant automatic counting of transcripts in 3.pdf:application/pdf},
}

@article{de_chaumont_icy_2012,
	title = {Icy: an open bioimage informatics platform for extended reproducible research},
	volume = {9},
	copyright = {2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1548-7105},
	shorttitle = {Icy},
	url = {https://www.nature.com/articles/nmeth.2075},
	doi = {10.1038/nmeth.2075},
	abstract = {Icy is a collaborative platform for biological image analysis that extends reproducible research principles by facilitating and stimulating the contribution and sharing of algorithm-based tools and protocols between researchers.},
	language = {en},
	number = {7},
	urldate = {2022-05-17},
	journal = {Nature Methods},
	author = {de Chaumont, Fabrice and Dallongeville, Stéphane and Chenouard, Nicolas and Hervé, Nicolas and Pop, Sorin and Provoost, Thomas and Meas-Yedid, Vannary and Pankajakshan, Praveen and Lecomte, Timothée and Le Montagner, Yoann and Lagache, Thibault and Dufour, Alexandre and Olivo-Marin, Jean-Christophe},
	month = jul,
	year = {2012},
	keywords = {Bioinformatics, Imaging},
	pages = {690--696},
	file = {Snapshot:/Users/arthur/Zotero/storage/82XCAR5N/nmeth.html:text/html},
}

@article{ershov_trackmate_2022,
	title = {{TrackMate} 7: integrating state-of-the-art segmentation algorithms into tracking pipelines},
	copyright = {2022 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	shorttitle = {{TrackMate} 7},
	url = {https://www.nature.com/articles/s41592-022-01507-1},
	doi = {10.1038/s41592-022-01507-1},
	abstract = {TrackMate is an automated tracking software used to analyze bioimages and is distributed as a Fiji plugin. Here, we introduce a new version of TrackMate. TrackMate 7 is built to address the broad spectrum of modern challenges researchers face by integrating state-of-the-art segmentation algorithms into tracking pipelines. We illustrate qualitatively and quantitatively that these new capabilities function effectively across a wide range of bio-imaging experiments.},
	urldate = {2022-06-21},
	journal = {Nature Methods},
	author = {Ershov, Dmitry and Phan, Minh-Son and Pylvänäinen, Joanna W. and Rigaud, Stéphane U. and Le Blanc, Laure and Charles-Orszag, Arthur and Conway, James R. W. and Laine, Romain F. and Roy, Nathan H. and Bonazzi, Daria and Duménil, Guillaume and Jacquemet, Guillaume and Tinevez, Jean-Yves},
	year = {2022},
	keywords = {Image processing, Software},
	pages = {1--4}
}

@article{perkel_starfish_2019,
	title = {Starfish enterprise: finding {RNA} patterns in single cells},
	volume = {572},
	copyright = {2021 Nature},
	shorttitle = {Starfish enterprise},
	url = {https://www.nature.com/articles/d41586-019-02477-9},
	doi = {10.1038/d41586-019-02477-9},
	abstract = {Combining the data-analysis tool Starfish with technologies to pinpoint RNA’s cellular locations can add spatial detail to in situ transcriptomics.},
	language = {en},
	number = {7770},
	urldate = {2022-05-17},
	journal = {Nature},
	author = {Perkel, Jeffrey M.},
	month = aug,
	year = {2019},
	keywords = {Computational biology and bioinformatics, Imaging, Technology, Transcriptomics},
	pages = {549--551},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/T2SDJQX3/Perkel - 2019 - Starfish enterprise finding RNA patterns in singl.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/2M6PP5B8/d41586-019-02477-9.html:text/html},
}

@article{eichenberger_deepblink_2021,
	title = {{deepBlink}: threshold-independent detection and localization of diffraction-limited spots},
	volume = {49},
	issn = {0305-1048},
	shorttitle = {{deepBlink}},
	url = {https://doi.org/10.1093/nar/gkab546},
	doi = {10.1093/nar/gkab546},
	abstract = {Detection of diffraction-limited spots in single-molecule microscopy images is traditionally performed with mathematical operators designed for idealized spots. This process requires manual tuning of parameters that is time-consuming and not always reliable. We have developed deepBlink, a neural network-based method to detect and localize spots automatically. We demonstrate that deepBlink outperforms other state-of-the-art methods across six publicly available datasets containing synthetic and experimental data.},
	number = {13},
	urldate = {2021-09-14},
	journal = {Nucleic Acids Research},
	author = {Eichenberger, Bastian Th and Zhan, YinXiu and Rempfler, Markus and Giorgetti, Luca and Chao, Jeffrey A},
	month = jul,
	year = {2021},
	pages = {7292--7297},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/K33TTFZT/Eichenberger et al. - 2021 - deepBlink threshold-independent detection and loc.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/AXDWRZN3/6312733.html:text/html},
}

@article{bahry_rs-fish_2021,
	title = {{RS}-{FISH}: {Precise}, interactive, fast, and scalable {FISH} spot detection},
	shorttitle = {{RS}-{FISH}},
	url = {https://www.biorxiv.org/content/10.1101/2021.03.09.434205v2},
	abstract = {Fluorescent in-situ hybridization (FISH)-based methods are powerful tools to study molecular processes with subcellular resolution, relying on accurate identification and localization of diffraction-limited spots in microscopy images. We developed the Radial Symmetry-FISH (RS-FISH) software that accurately, robustly, and quickly detects single-molecule spots in two and three dimensions, making it applicable to several key assays, including single-molecule FISH (smFISH), spatial transcriptomics, and spatial genomics. RS-FISH allows interactive parameter tuning and scales to large sets of images as well as tera-byte sized image volumes such as entire brain scans using straight-forward distributed processing on workstations, clusters, and in the cloud.},
	urldate = {2022-05-17},
	institution = {bioRxiv},
	journal = {bioRxiv},
	author = {Bahry, Ella and Breimann, Laura and Zouinkhi, Marwan and Epstein, Leo and Kolyvanov, Klim and Long, Xi and Harrington, Kyle I. S. and Lionnet, Timothée and Preibisch, Stephan},
	month = oct,
	year = {2021},
	doi = {10.1101/2021.03.09.434205}
}

@article{lagache_statistical_2015,
	title = {Statistical analysis of molecule colocalization in bioimaging},
	volume = {87},
	issn = {1552-4930},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cyto.a.22629},
	doi = {10.1002/cyto.a.22629},
	abstract = {The quantitative analysis of molecule interactions in bioimaging is key for understanding the molecular orchestration of cellular processes and is generally achieved through the study of the spatial colocalization between the different populations of molecules. Colocalization methods are traditionally divided into pixel-based methods that measure global correlation coefficients from the overlap between pixel intensities in different color channels, and object-based methods that first segment molecule spots and then analyze their spatial distributions with second-order statistics. Here, we present a review of such colocalization methods and give a quantitative comparison of their relative merits in different types of biological applications and contexts. We show on synthetic and biological images that object-based methods are more robust statistically than pixel-based methods, and allow moreover to quantify accurately the number of colocalized molecules. © 2015 International Society for Advancement of Cytometry},
	number = {6},
	urldate = {2022-05-17},
	journal = {Cytometry Part A},
	author = {Lagache, Thibault and Sauvonnet, Nathalie and Danglot, Lydia and Olivo-Marin, Jean-Christophe},
	year = {2015},
	keywords = {colocalization, endocytosis, light microscopy, quantitative measurements, spatial statistics},
	pages = {568--579},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/65CJ7K7A/Lagache et al. - 2015 - Statistical analysis of molecule colocalization in.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/4DUMTVE3/cyto.a.html:text/html},
}

@article{ruusuvuori_evaluation_2010,
	title = {Evaluation of methods for detection of fluorescence labeled subcellular objects in microscope images},
	volume = {11},
	issn = {1471-2105},
	url = {https://doi.org/10.1186/1471-2105-11-248},
	doi = {10.1186/1471-2105-11-248},
	abstract = {Several algorithms have been proposed for detecting fluorescently labeled subcellular objects in microscope images. Many of these algorithms have been designed for specific tasks and validated with limited image data. But despite the potential of using extensive comparisons between algorithms to provide useful information to guide method selection and thus more accurate results, relatively few studies have been performed.},
	number = {1},
	urldate = {2022-05-17},
	journal = {BMC Bioinformatics},
	author = {Ruusuvuori, Pekka and Äijö, Tarmo and Chowdhury, Sharif and Garmendia-Torres, Cecilia and Selinummi, Jyrki and Birbaumer, Mirko and Dudley, Aimée M. and Pelkmans, Lucas and Yli-Harja, Olli},
	month = may,
	year = {2010},
	keywords = {Human Osteosarcoma Cell Line, Kernel Density Estimation, Reference Result, Simulated Image, Spot Detection},
	pages = {248},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/F55C3XVQ/Ruusuvuori et al. - 2010 - Evaluation of methods for detection of fluorescenc.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/MRPNVRWB/1471-2105-11-248.html:text/html},
}

@article{walt_scikit-image_2014,
	title = {scikit-image: image processing in {Python}},
	volume = {2},
	issn = {2167-8359},
	shorttitle = {scikit-image},
	url = {https://peerj.com/articles/453},
	doi = {10.7717/peerj.453},
	abstract = {scikit-image is an image processing library that implements algorithms and utilities for use in research, education and industry applications. It is released under the liberal Modified BSD open source license, provides a well-documented API in the Python programming language, and is developed by an active, international team of collaborators. In this paper we highlight the advantages of open source to achieve the goals of the scikit-image library, and we showcase several real-world image processing applications that use scikit-image. More information can be found on the project homepage, http://scikit-image.org.},
	language = {en},
	urldate = {2022-05-17},
	journal = {PeerJ},
	author = {Walt, Stéfan van der and Schönberger, Johannes L. and Nunez-Iglesias, Juan and Boulogne, François and Warner, Joshua D. and Yager, Neil and Gouillart, Emmanuelle and Yu, Tony},
	month = jun,
	year = {2014},
	pages = {e453},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/JH7CQA7A/Walt et al. - 2014 - scikit-image image processing in Python.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/RGBGPQW2/453.html:text/html},
}

@article{bertin_sextractor_1996,
	title = {{SExtractor}: {Software} for source extraction},
	volume = {117},
	copyright = {© European Southern Observatory (ESO), 1996},
	issn = {0365-0138, 1286-4846},
	shorttitle = {{SExtractor}},
	url = {https://aas.aanda.org/articles/aas/abs/1996/08/ds1060/ds1060.html},
	doi = {10.1051/aas:1996164},
	abstract = {We present the automated techniques we have developed for new software that optimally detects, deblends, measures and classifies sources from astronomical images: SExtractor ({\textless}i{\textgreater}Source Extractor {\textless}i/{\textgreater}). We show that a very reliable star/galaxy separation can be achieved on most images using a neural network trained with {\textless}i{\textgreater}simulated{\textless}i/{\textgreater} images. Salient features of SExtractor include its ability to work on very large images, with minimal human intervention, and to deal with a wide variety of object shapes and magnitudes. It is therefore particularly suited to the analysis of large extragalactic surveys.},
	language = {en},
	number = {2},
	urldate = {2022-05-17},
	journal = {Astronomy and Astrophysics Supplement Series},
	author = {Bertin, E. and Arnouts, S.},
	month = jun,
	year = {1996},
	pages = {393--404},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/ADQSTSZ4/Bertin and Arnouts - 1996 - SExtractor Software for source extraction.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/E5CXSKGJ/ds1060.html:text/html},
}

@article{smal_quantitative_2010,
	title = {Quantitative {Comparison} of {Spot} {Detection} {Methods} in {Fluorescence} {Microscopy}},
	volume = {29},
	issn = {1558-254X},
	doi = {10.1109/TMI.2009.2025127},
	abstract = {Quantitative analysis of biological image data generally involves the detection of many subresolution spots. Especially in live cell imaging, for which fluorescence microscopy is often used, the signal-to-noise ratio (SNR) can be extremely low, making automated spot detection a very challenging task. In the past, many methods have been proposed to perform this task, but a thorough quantitative evaluation and comparison of these methods is lacking in the literature. In this paper, we evaluate the performance of the most frequently used detection methods for this purpose. These include seven unsupervised and two supervised methods. We perform experiments on synthetic images of three different types, for which the ground truth was available, as well as on real image data sets acquired for two different biological studies, for which we obtained expert manual annotations to compare with. The results from both types of experiments suggest that for very low SNRs ( ¿ 2), the supervised (machine learning) methods perform best overall. Of the unsupervised methods, the detectors based on the so-called h -dome transform from mathematical morphology or the multiscale variance-stabilizing transform perform comparably, and have the advantage that they do not require a cumbersome learning stage. At high SNRs ( {\textgreater} 5), the difference in performance of all considered detectors becomes negligible.},
	number = {2},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Smal, Ihor and Loog, Marco and Niessen, Wiro and Meijering, Erik},
	month = feb,
	year = {2010},
	keywords = {Biomedical imaging, Detectors, Fluorescence, Fluorescence microscopy, Image analysis, image filtering, machine learning, Machine learning, noise reduction, object detection, Object detection, Optical imaging, Optical microscopy, Proteins, Signal to noise ratio},
	pages = {282--301},
	file = {IEEE Xplore Abstract Record:/Users/arthur/Zotero/storage/P5YH7TUA/5109713.html:text/html},
}

@article{bouilhol_deepspot_2022,
	title = {{DeepSpot}: a deep neural network for {RNA} spot enhancement in {smFISH} microscopy images},
	issn = {2633-903X},
	shorttitle = {{DeepSpot}},
	url = {https://www.cambridge.org/core/journals/biological-imaging/article/deepspot-a-deep-neural-network-for-rna-spot-enhancement-in-smfish-microscopy-images/3D022F6E91BA5B101C9A019B4C2B1A96},
	doi = {10.1017/S2633903X22000034},
	abstract = {//static.cambridge.org/content/id/urn\%3Acambridge.org\%3Aid\%3Aarticle\%3AS2633903X22000034/resource/name/firstPage-S2633903X22000034a.jpg},
	language = {en},
	urldate = {2022-05-17},
	journal = {Biological Imaging},
	author = {Bouilhol, Emmanuel and Savulescu, Anca Flavia and Lefevre, Edgar and Dartigues, Benjamin and Brackin, Robyn and Nikolski, Macha},
	month = apr,
	year = {2022},
	pages = {1--18},
	file = {Full Text PDF:/Users/arthur/Zotero/storage/K7UQV557/Bouilhol et al. - 2022 - DeepSpot a deep neural network for RNA spot enhan.pdf:application/pdf;Snapshot:/Users/arthur/Zotero/storage/8SR7JAM7/3D022F6E91BA5B101C9A019B4C2B1A96.html:text/html},
}

@inproceedings{ester_density-based_1996,
	address = {Portland, Oregon},
	series = {{KDD}'96},
	title = {A density-based algorithm for discovering clusters in large spatial databases with noise},
	abstract = {Clustering algorithms are attractive for the task of class identification in spatial databases. However, the application to large spatial databases rises the following requirements for clustering algorithms: minimal requirements of domain knowledge to determine the input parameters, discovery of clusters with arbitrary shape and good efficiency on large databases. The well-known clustering algorithms offer no solution to the combination of these requirements. In this paper, we present the new clustering algorithm DBSCAN relying on a density-based notion of clusters which is designed to discover clusters of arbitrary shape. DBSCAN requires only one input parameter and supports the user in determining an appropriate value for it. We performed an experimental evaluation of the effectiveness and efficiency of DBSCAN using synthetic data and real data of the SEQUOIA 2000 benchmark. The results of our experiments demonstrate that (1) DBSCAN is significantly more effective in discovering clusters of arbitrary shape than the well-known algorithm CLAR-ANS, and that (2) DBSCAN outperforms CLARANS by a factor of more than 100 in terms of efficiency.},
	urldate = {2022-06-15},
	booktitle = {Proceedings of the {Second} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {AAAI Press},
	author = {Ester, Martin and Kriegel, Hans-Peter and Sander, Jörg and Xu, Xiaowei},
	month = aug,
	year = {1996},
	keywords = {arbitrary shape of clusters, clustering algorithms, efficiency on large spatial databases, handling nlj4-275oise},
	pages = {226--231},
}

@inproceedings{wu_connected_component_2005,
	author = {Wu, Kesheng and Otoo, Ekow and Shoshani, Arie},
	title = {Optimizing connected component labeling algorithms},
	volume = {5747},
	booktitle = {Medical Imaging 2005: Image Processing},
	organization = {International Society for Optics and Photonics},
	publisher = {SPIE},
	pages = {1965--1976},
	keywords = {pattern recognition, segmentation},
	year = {2005},
	doi = {10.1117/12.596105},
	URL = {https://doi.org/10.1117/12.596105}
}

@article{crouse_linear_assignment_2016,
	author={Crouse, David F.},
	journal={IEEE Transactions on Aerospace and Electronic Systems},
	title={On implementing 2D rectangular assignment algorithms},
	year={2016},
	volume={52},
	number={4},
	pages={1679-1696},
	doi={10.1109/TAES.2016.140952}
}

@article{scikit-learn,
	title={Scikit-learn: Machine Learning in {P}ython},
	author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
		 and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
		 and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
		 Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
	journal={Journal of Machine Learning Research},
	volume={12},
	pages={2825--2830},
	year={2011}
}

@article{CORNES_2022,
	title = {piRNAs initiate transcriptional silencing of spermatogenic genes during C. elegans germline development},
	journal = {Developmental Cell},
	volume = {57},
	number = {2},
	pages = {180-196.e7},
	year = {2022},
	issn = {1534-5807},
	doi = {https://doi.org/10.1016/j.devcel.2021.11.025},
	url = {https://www.sciencedirect.com/science/article/pii/S1534580721009898},
	author = {Eric Cornes and Loan Bourdon and Meetali Singh and Florian Mueller and Piergiuseppe Quarato and Erik Wernersson and Magda Bienko and Blaise Li and Germano Cecere},
	keywords = {piRNAs, small RNAs, RNAi, , germ granules, transcriptional silencing, epigenetics, spermatogenesis, germline development, fertility},
	abstract = {Summary
	Eukaryotic genomes harbor invading transposable elements that are silenced by PIWI-interacting RNAs (piRNAs) to maintain genome integrity in animal germ cells. However, whether piRNAs also regulate endogenous gene expression programs remains unclear. Here, we show that C. elegans piRNAs trigger the transcriptional silencing of hundreds of spermatogenic genes during spermatogenesis, promoting sperm differentiation and function. This silencing signal requires piRNA-dependent small RNA biogenesis and loading into downstream nuclear effectors, which correlates with the dynamic reorganization of two distinct perinuclear biomolecular condensates present in germ cells. In addition, the silencing capacity of piRNAs is temporally counteracted by the Argonaute CSR-1, which targets and licenses spermatogenic gene transcription. The spatial and temporal overlap between these opposing small RNA pathways contributes to setting up the timing of the spermatogenic differentiation program. Thus, our work identifies a prominent role for piRNAs as direct regulators of endogenous transcriptional programs during germline development and gamete differentiation.}
}

@article{Otsu_1979,
	author={Otsu, Nobuyuki},
	journal={IEEE Transactions on Systems, Man, and Cybernetics},
	title={A Threshold Selection Method from Gray-Level Histograms},
	year={1979},
	volume={9},
	number={1},
	pages={62-66},
	doi={10.1109/TSMC.1979.4310076}
}

@article{astropy_2018,
	doi = {10.3847/1538-3881/aabc4f},
	url = {https://doi.org/10.3847/1538-3881/aabc4f},
	year = 2018,
	month = {aug},
	publisher = {American Astronomical Society},
	volume = {156},
	number = {3},
	pages = {123},
	author = {A. M. Price-Whelan and B. M. Sip{\H{o}}cz and H. M. Günther and P. L. Lim and S. M. Crawford and S. Conseil and D. L. Shupe and M. W. Craig and N. Dencheva and A. Ginsburg and J. T. VanderPlas and L. D. Bradley and D. P{\'{e}}rez-Su{\'{a}}rez and M. de Val-Borro and T. L. Aldcroft and K. L. Cruz and T. P. Robitaille and E. J. Tollerud and C. Ardelean and T. Babej and Y. P. Bach and M. Bachetti and A. V. Bakanov and S. P. Bamford and G. Barentsen and P. Barmby and A. Baumbach and K. L. Berry and F. Biscani and M. Boquien and K. A. Bostroem and L. G. Bouma and G. B. Brammer and E. M. Bray and H. Breytenbach and H. Buddelmeijer and D. J. Burke and G. Calderone and J. L. Cano Rodr{\'{\i}}guez and M. Cara and J. V. M. Cardoso and S. Cheedella and Y. Copin and L. Corrales and D. Crichton and D. D'Avella and C. Deil and {\'{E}}. Depagne and J. P. Dietrich and A. Donath and M. Droettboom and N. Earl and T. Erben and S. Fabbro and L. A. Ferreira and T. Finethy and R. T. Fox and L. H. Garrison and S. L. J. Gibbons and D. A. Goldstein and R. Gommers and J. P. Greco and P. Greenfield and A. M. Groener and F. Grollier and A. Hagen and P. Hirst and D. Homeier and A. J. Horton and G. Hosseinzadeh and L. Hu and J. S. Hunkeler and {\v{Z}}. Ivezi{\'{c}} and A. Jain and T. Jenness and G. Kanarek and S. Kendrew and N. S. Kern and W. E. Kerzendorf and A. Khvalko and J. King and D. Kirkby and A. M. Kulkarni and A. Kumar and A. Lee and D. Lenz and S. P. Littlefair and Z. Ma and D. M. Macleod and M. Mastropietro and C. McCully and S. Montagnac and B. M. Morris and M. Mueller and S. J. Mumford and D. Muna and N. A. Murphy and S. Nelson and G. H. Nguyen and J. P. Ninan and M. Nöthe and S. Ogaz and S. Oh and J. K. Parejko and N. Parley and S. Pascual and R. Patil and A. A. Patil and A. L. Plunkett and J. X. Prochaska and T. Rastogi and V. Reddy Janga and J. Sabater and P. Sakurikar and M. Seifert and L. E. Sherbert and H. Sherwood-Taylor and A. Y. Shih and J. Sick and M. T. Silbiger and S. Singanamalla and L. P. Singer and P. H. Sladen and K. A. Sooley and S. Sornarajah and O. Streicher and P. Teuben and S. W. Thomas and G. R. Tremblay and J. E. H. Turner and V. Terr{\'{o}}n and M. H. van Kerkwijk and A. de la Vega and L. L. Watkins and B. A. Weaver and J. B. Whitmore and J. Woillez and V. Zabalza and Astropy Contributors},
	title = {The Astropy Project: Building an Open-science Project and Status of the v2.0 Core Package},
	journal = {The Astronomical Journal},
	abstract = {The Astropy Project supports and fosters the development of open-source and openly developed Python packages that provide commonly needed functionality to the astronomical community. A key element of the Astropy Project is the core package astropy, which serves as the foundation for more specialized projects and packages. In this article, we provide an overview of the organization of the Astropy project and summarize key features in the core package, as of the recent major release, version 2.0. We then describe the project infrastructure designed to facilitate and support development for a broader ecosystem of interoperable packages. We conclude with a future outlook of planned new features and directions for the broader Astropy Project.}
}

@software{larry_bradley_2020_4044744,
	author       = {Larry Bradley and
					Brigitta Sip{\H o}cz and
					Thomas Robitaille and
					Erik Tollerud and
					Z\`e Vin{\'{\i}}cius and
					Christoph Deil and
					Kyle Barbary and
					Tom J Wilson and
					Ivo Busko and
					Hans Moritz G{\"u}nther and
					Mihai Cara and
					Simon Conseil and
					Azalee Bostroem and
					Michael Droettboom and
					E. M. Bray and
					Lars Andersen Bratholm and
					P. L. Lim and
					Geert Barentsen and
					Matt Craig and
					Sergio Pascual and
					Gabriel Perren and
					Johnny Greco and
					Axel Donath and
					Miguel de Val-Borro and
					Wolfgang Kerzendorf and
					Yoonsoo P. Bach and
					Benjamin Alan Weaver and
					Francesco D'Eugenio and
					Harrison Souchereau and
					Leonardo Ferreira},
	title        = {astropy/photutils: 1.0.0},
	month        = sep,
	year         = 2020,
	publisher    = {Zenodo},
	version      = {1.0.0},
	doi          = {10.5281/zenodo.4044744},
	url          = {https://doi.org/10.5281/zenodo.4044744}
}

@inproceedings{Ronneberger_2015,
	author="Ronneberger, Olaf
	and Fischer, Philipp
	and Brox, Thomas",
	title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
	booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
	year="2015",
	publisher="Springer International Publishing",
	address="Cham",
	pages="234--241",
	abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
	isbn="978-3-319-24574-4"
}

@inproceedings{Hamaguchi_2018,
	author={Hamaguchi, Ryuhei and Fujita, Aito and Nemoto, Keisuke and Imaizumi, Tomoyuki and Hikosaka, Shuhei},
	booktitle={2018 IEEE Winter Conference on Applications of Computer Vision (WACV)},
	title={Effective Use of Dilated Convolutions for Segmenting Small Object Instances in Remote Sensing Imagery},
	year={2018},
	pages={1442-1450},
	doi={10.1109/WACV.2018.00162}
}

@inproceedings{He_2016,
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	title={Deep Residual Learning for Image Recognition},
	year={2016},
	pages={770-778},
	doi={10.1109/CVPR.2016.90}
}

@inproceedings{Redmon_2016_CVPR,
	author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
	title = {You Only Look Once: Unified, Real-Time Object Detection},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2016}
}

@article{FREUND1997119,
	title = {A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting},
	journal = {Journal of Computer and System Sciences},
	volume = {55},
	number = {1},
	pages = {119-139},
	year = {1997},
	issn = {0022-0000},
	doi = {https://doi.org/10.1006/jcss.1997.1504},
	url = {https://www.sciencedirect.com/science/article/pii/S002200009791504X},
	author = {Yoav Freund and Robert E Schapire},
	abstract = {In the first part of the paper we consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework. The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting. We show that the multiplicative weight-update Littlestone–Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems. We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games, and prediction of points in Rn. In the second part of the paper we apply the multiplicative weight-update technique to derive a new boosting algorithm. This boosting algorithm does not require any prior knowledge about the performance of the weak learning algorithm. We also study generalizations of the new boosting algorithm to the problem of learning functions whose range, rather than being binary, is an arbitrary finite set or a bounded segment of the real line.}
}

@article{Dufour2005,
  author={Dufour, A. and Shinin, V. and Tajbakhsh, S. and Guillen-Aghion, N. and Olivo-Marin, J.-C. and Zimmer, C.},
  journal={IEEE Transactions on Image Processing},
  title={Segmenting and tracking fluorescent cells in dynamic 3-D microscopy with coupled active surfaces},
  year={2005},
  volume={14},
  number={9},
  pages={1396-1410},
  doi={10.1109/TIP.2005.852790}
}

@article{Wahlby2002,
	title = {Algorithms for cytoplasm segmentation of fluorescence labelled cells.},
	volume = {24},
	issn = {0921-8912},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/12446959},
	abstract = {Automatic cell segmentation has various applications in cytometry, and while the nucleus is often very distinct and easy to identify, the cytoplasm provides a lot more challenge. A new combination of image analysis algorithms for segmentation of cells imaged by fluorescence microscopy is presented. The algorithm consists of an image pre-processing step, a general segmentation and merging step followed by a segmentation quality measurement. The quality measurement consists of a statistical analysis of a number of shape descriptive features. Objects that have features that differ to that of correctly segmented single cells can be further processed by a splitting step. By statistical analysis we therefore get a feedback system for separation of clustered cells. After the segmentation is completed, the quality of the final segmentation is evaluated. By training the algorithm on a representative set of training images, the algorithm is made fully automatic for subsequent images created under similar conditions. Automatic cytoplasm segmentation was tested on CHO-cells stained with calcein. The fully automatic method showed between 89\% and 97\% correct segmentation as compared to manual segmentation.},
	number = {2-3},
	journal = {Analytical cellular pathology : the journal of the European Society for Analytical Cellular Pathology},
	author = {Wählby, Carolina and Lindblad, Joakim and Vondrus, Mikael and Bengtsson, Ewert and Björkesten, Lennart},
	year = {2002},
	pmid = {12446959},
	keywords = {Animals, Humans, Microscopy, Fluorescence, Microscopy, Fluorescence: methods, Image Processing, Computer-Assisted, Flow Cytometry, Cytoplasm, Algorithms, Cytoplasm: ultrastructure, Flow Cytometry: methods},
	pages = {101--11}
}

@book{Soille2003,
	edition = {2},
	title = {Morphological {Image} {Analysis}: {Principles} and {Applications}},
	isbn = {3-540-42988-3},
	author = {Soille, Pierre},
	year = {2003}
}

@inproceedings{Beucher1979,
	title = {Use of watershed in contour detection},
	booktitle = {International {Workshop} on image processing: real-time {Edge} and {Motion} detection/estimation},
	author = {Beucher, Serge and Lantuéjoul, Christian},
	year = {1979}
}

@book{Serra1983,
	address = {Orlando, FL, USA},
	title = {Image {Analysis} and {Mathematical} {Morphology}},
	isbn = {0-12-637240-3},
	publisher = {Academic Press, Inc.},
	author = {Serra, Jean},
	year = {1983}
}

@article{Godinez2017,
	title = {A multi-scale convolutional neural network for phenotyping high-content cellular images},
	volume = {33},
	issn = {1367-4803},
	url = {https://doi.org/10.1093/bioinformatics/btx069},
	doi = {10.1093/bioinformatics/btx069},
	abstract = {Identifying phenotypes based on high-content cellular images is challenging. Conventional image analysis pipelines for phenotype identification comprise multiple independent steps, with each step requiring method customization and adjustment of multiple parameters. Here, we present an approach based on a multi-scale convolutional neural network (M-CNN) that classifies, in a single cohesive step, cellular images into phenotypes by using directly and solely the images’ pixel intensity values. The only parameters in the approach are the weights of the neural network, which are automatically optimized based on training images. The approach requires no a priori knowledge or manual customization, and is applicable to single- or multi-channel images displaying single or multiple cells. We evaluated the classification performance of the approach on eight diverse benchmark datasets. The approach yielded overall a higher classification accuracy compared with state-of-the-art results, including those of other deep CNN architectures. In addition to using the network to simply obtain a yes-or-no prediction for a given phenotype, we use the probability outputs calculated by the network to quantitatively describe the phenotypes. This study shows that these probability values correlate with chemical treatment concentrations. This finding validates further our approach and enables chemical treatment potency estimation via CNNs.The network specifications and solver definitions are provided in Supplementary Software 1.Supplementary data are available at Bioinformatics online.},
	number = {13},
	journal = {Bioinformatics},
	author = {Godinez, William J and Hossain, Imtiaz and Lazic, Stanley E and Davies, John W and Zhang, Xian},
	year = {2017},
	keywords = {High Content Screening, Deep Learning},
	pages = {2010--2019}
}

@article{Walter2007,
	title = {Automatic detection of microaneurysms in color fundus images.},
	volume = {11},
	number = {6},
	journal = {Medical Image Analysis},
	author = {Walter, Thomas and Massin, Pascale and Erginay, Ali and Ordonez, Richard and Jeulin, Clothilde and Klein, Jean-Claude},
	year = {2007},
	pages = {555--66}
}

@article{Lindeberg2015,
	title = {Image {Matching} {Using} {Generalized} {Scale}-{Space} {Interest} {Points}},
	volume = {52},
	issn = {0924-9907, 1573-7683},
	url = {http://link.springer.com/10.1007/s10851-014-0541-0},
	doi = {10.1007/s10851-014-0541-0},
	number = {1},
	urldate = {2022-11-05},
	journal = {Journal of Mathematical Imaging and Vision},
	author = {Lindeberg, Tony},
	year = {2015},
	pages = {3--36}
}

@article{Olivo-Marin2002,
	title = {Extraction of spots in biological images using multiscale products},
	volume = {35},
	issn = {00313203},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0031320301001273},
	doi = {10.1016/S0031-3203(01)00127-3},
	abstract = {We present a new method to detect and count bright spots in uorescence images coming from biological immunomicroscopy experiments. It is based on the multiscale product of subband images resulting from the aÂ trous wavelet transform decomposition of the original image, after thresholding of non-signiÿcant coe cients. The multiscale correlation of the ÿltered wavelet coe cients, which allows to enhance multiscale peaks due to spots while reducing noise, combines information coming from di erent levels of resolution and gives a clear and distinctive chacterization of the spots. Results are presented for the analysis of typical immuno uorescence images. ? 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.},
	number = {9},
	urldate = {2022-11-05},
	journal = {Pattern Recognition},
	author = {Olivo-Marin, Jean-Christophe},
	year = {2002},
	pages = {1989--1996}
}